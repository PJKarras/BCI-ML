{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Takes GPP and date information from old master file and creates a new Machine Learning Master File\\n   With one column representing file names for the converted CSVs and the other column being their respective\\n   GPPs as pulled from the old master file or calculated with linear interpolation'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peter Karras 2020\n",
    "'''Takes GPP and date information from old master file and creates a new Machine Learning Master File\n",
    "   With one column representing file names for the converted CSVs and the other column being their respective\n",
    "   GPPs as pulled from the old master file or calculated with linear interpolation'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a string that represents name of csv file and \n",
    "# converts that string to one that matches the date string present\n",
    "# in the old master file (old master file refers to the raw excel file\n",
    "# filled with extraneous data from BCI)that contains the date/times \n",
    "# for recorded GPP values\n",
    "def change_csv_date(csv):\n",
    "    minDivFiveFlag = True\n",
    "    year = csv[2:4]\n",
    "    month = csv[5:7]\n",
    "    day = csv[8:10]\n",
    "    hour = csv[11:13]\n",
    "    minute = csv[14:16]\n",
    "    second = \"00\"\n",
    "    if (int(minute) % 5) != 0:\n",
    "        print(\"THIS:\", csv, \"minute not divisible by 5\")\n",
    "        minDivFiveFlag = False\n",
    "    if(int(hour) == 0):\n",
    "        hour = \"0\"\n",
    "    elif(int(hour) < 10):\n",
    "        hour = hour[1:2]\n",
    "    # No leading zeroes in day or month\n",
    "    if(int(month) < 10):\n",
    "        month = month[1:2]\n",
    "    if(int(day) < 10):\n",
    "        day = day[1:2]\n",
    "    result = month + \"/\" + day + \"/\" + year + \" \" + hour + \":\" + minute #+ \":\" + second + \" \" + timeDay\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE MAKE MASTER TO CREATE MULTIPLE populatedGPP files that hold mar, april, may etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that checks if time/date is at 00 minutes\n",
    "def check_zero_time_min(csv):\n",
    "    if csv[14:16] == \"00\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#  and 30 minutes\n",
    "def check_thirty_time_min(csv):\n",
    "    if csv[14:16] == \"30\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "# and at specific hour\n",
    "def check_spec_time_hour(csv, hour):\n",
    "    if csv[11:13]==hour:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Takes in csv date (in format 'YYYY_MM_DD_HH_MM_bci_t') and checks to see if minutes are divisble by div\n",
    "def check_csv_date(csv, div):\n",
    "    result = False\n",
    "    minute = int(csv[14:16])\n",
    "    remainder = minute % div\n",
    "    if(remainder == 0):\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "    return result\n",
    "\n",
    "# Get int value of hour\n",
    "def get_hour_int(csv):\n",
    "    return int(csv[11:13])\n",
    "\n",
    "def get_min_int(csv):\n",
    "    return int(csv[14:16])\n",
    "    \n",
    "\n",
    "# Takes in csv date (in format 'YYYY_MM_DD_HH_MM_bci_t') and checks to see if it falls within the \"morning\" 4:00am - 12:00pm\n",
    "def time_check_csv_date(csv, regex):\n",
    "    return not (None == regex.match(csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(check_thirty_time_min(\"2015_03_14_12_30_bci_t.csv\"))\n",
    "print(check_spec_time_hour(\"2015_03_14_09_30_bci_t.csv\",\"09\"))\n",
    "print(get_min_int(\"2015_03_14_09_59_bci_t.csv\")%30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set user inputed values\n",
    "Date Format: YYYY_MM_DD_HH_MM_bci_t\n",
    "'''\n",
    "masterfileLocation = r\"C:\\Users\\Peter\\Desktop\\Thermo_R_Code\\FinalThermo\\new2\"\n",
    "masterFileName = \"all-30min-Apr2018_working.csv\"\n",
    "#regex_time_range = re.compile(\"2015_.._.._(0[4-9]_..|1[01]_..|12_00)_bci_t\")\n",
    "#regex_time_range = re.compile(\"2015_.._.._(1[4-9]_..|20_00)_bci_t\")\n",
    "regex_time_range = re.compile(\"2015_.._.._(0[4-9]_..|1[0-9]_..|20_00)_bci_t\")\n",
    "# 24 hour clock\n",
    "pop_GPPS_file = \"populatedGPPsDAYTIME.csv\"\n",
    "graphTitle = \"Daytime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37150\n",
      "2015_09_30_20_00_bci_t.csv\n"
     ]
    }
   ],
   "source": [
    "# Grabs all GPP values and dates from master file (as defined above)\n",
    "masterfileLocation = r\"C:\\Users\\Peter\\Desktop\\Thermo_R_Code\\FinalThermo\\new2\"\n",
    "os.chdir(masterfileLocation)\n",
    "col_list = [\"date\", \"GPP\"]\n",
    "masterFileName = \"all-30min-Apr2018_working.csv\"\n",
    "dateGPPList = pd.read_csv(masterFileName, usecols=col_list) \n",
    "dateGPPList = dateGPPList.set_index(\"date\")\n",
    "\n",
    "# Create list of all avaialble thermal CSV values\n",
    "csvdataLocation = r\"C:\\Users\\Peter\\Desktop\\Thermo_R_Code\\FinalThermo\\new2\\csvdataFULL\\BCIML_Dataset\"\n",
    "(_, _, csvfiles) = next(os.walk(csvdataLocation))\n",
    "# Remove any items that arent thermal image csv files (in this case filtering by file name)\n",
    "csvfiles = [item for item in csvfiles if 'bci_t' in item]\n",
    "# Remove files not within date range with regex\n",
    "csvfiles = [item for item in csvfiles if time_check_csv_date(item,regex_time_range)]\n",
    "\n",
    "######################################\n",
    "\"\"\"\n",
    "TESTING TEMPORARY\n",
    "\"\"\"\n",
    "# print(len(csvfiles))\n",
    "# tempcsvfiles =list()\n",
    "# for i in range(200):\n",
    "#     print(csvfiles[i+194])\n",
    "#     tempcsvfiles.append(csvfiles[i+194])\n",
    "# csvfiles = tempcsvfiles\n",
    "# print(csvfiles)\n",
    "# print(len(csvfiles))\n",
    "#########################################\n",
    "print(len(csvfiles))\n",
    "print(csvfiles[len(csvfiles)-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37150\n",
      "28572\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "list_dict_full = list()\n",
    "csvfiles_iter = iter(csvfiles)\n",
    "print(\"before run\",len(csvfiles))\n",
    "\n",
    "current = next(csvfiles_iter, None)\n",
    "while(True):\n",
    "    counter += 1\n",
    "    # End of files break condition\n",
    "    if current == None:\n",
    "        break\n",
    "    # Increment until we hit the start of an appropriate interval start \n",
    "    # (one that has a corresponding recorded GPP value)\n",
    "    while(current != None and (get_min_int(current)%30) != 0):\n",
    "        current = next(csvfiles_iter, None)\n",
    "    if current == None:\n",
    "        break\n",
    "        \n",
    "    old_gpp = -101\n",
    "    # Go through full time interval, doing linear interpolation where possible\n",
    "    old_hour = get_hour_int(current)\n",
    "    while (current != None and get_hour_int(current) >= old_hour):\n",
    "        # If you are at the start of an interval, perform calculations for the next\n",
    "        # 30 mins worth of values\n",
    "        if get_min_int(current)%30 == 0:\n",
    "            try:\n",
    "                old_gpp = dateGPPList.at[change_csv_date(current),\"GPP\"]\n",
    "            except KeyError:\n",
    "                current = next(csvfiles_iter)\n",
    "                old_hour = get_hour_int(current)\n",
    "                continue\n",
    "            list_dict_30min = list()\n",
    "            list_dict_30min.append({\"GPP\":old_gpp, \"FILE\":current})\n",
    "            # Move onto values after 00 or 30. (05,10... or 35,40...)\n",
    "            # Add to list of dicts iff minutes divisible by 5\n",
    "            current = next(csvfiles_iter, None)\n",
    "            while len(list_dict_30min) < 6 and current != None and get_hour_int(current) >= old_hour:\n",
    "                if(get_min_int(current)%5 == 0):\n",
    "                    list_dict_30min.append({\"GPP\":-101, \"FILE\":current})\n",
    "                old_hour = get_hour_int(current)\n",
    "                current = next(csvfiles_iter, None)\n",
    "            if current == None:\n",
    "                break\n",
    "            while get_min_int(current)%5 != 0:\n",
    "                current = next(csvfiles_iter, None)\n",
    "            # On exit of inner loop we have a list of values with minute values that look like:\n",
    "            # 00 05 10 15 20 25 or 30 35 40 45 50 55\n",
    "            if current == None or len(list_dict_30min) < 6:\n",
    "                break\n",
    "            else:\n",
    "                try:\n",
    "                    increment = (dateGPPList.at[change_csv_date(current),\"GPP\"] - list_dict_30min[0]['GPP'])/6.0\n",
    "                except KeyError:\n",
    "                    old_hour = get_hour_int(current)\n",
    "                    continue\n",
    "                for i in range(1,6):\n",
    "                    temp_gpp_val = list_dict_30min[i-1]['GPP']+increment\n",
    "                    list_dict_30min[i].update({'GPP':temp_gpp_val})\n",
    "                list_dict_full.extend(list_dict_30min)\n",
    "        else:\n",
    "            current = next(csvfiles_iter, None)\n",
    "        if current != None:\n",
    "            old_hour = get_hour_int(current)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    # If list incomplete we have ticked into next day\n",
    "    if len(list_dict_30min) < 6:\n",
    "        continue\n",
    "        \n",
    "    # Iterate to next element\n",
    "    current = next(csvfiles_iter, None)\n",
    "\n",
    "print(\"after run\",len(list_dict_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28572\n"
     ]
    }
   ],
   "source": [
    "print(len(list_dict_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\Desktop\\Thermo_R_Code\\FinalThermo\\new2\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "MONTH_NAME = \"NOn\"\n",
    "n_epochs = 5\n",
    "batch_size = 6\n",
    "idNum = \"123\"\n",
    "file1 = open(\"stats_\"+MONTH_NAME+\"_\"+idNum+\".txt\",\"a\")\n",
    "file1.write(\"Epochs: \" + str(n_epochs) +\"\\n\")\n",
    "file1.write(\"Batch Size: \" + str(batch_size))\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This writes a NEW master file, with one column containing the\n",
    "# thermal csv file names, and the other column containing their\n",
    "# GPP values as determined from previous code. New file name is \n",
    "# determined by variable pop_GPPS_file\n",
    "\n",
    "import csv\n",
    "saveLocation = csvdataLocation\n",
    "os.chdir(saveLocation)\n",
    "#pop_GPPS_file = \"populatedGPPs.csv\"\n",
    "#pop_GPPS_file = input(\"Please type what you like the populatedGPP file to be called:\")\n",
    "csv_columns = ['FILE','GPP']\n",
    "try:\n",
    "    with open(pop_GPPS_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in list_dict_full:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_master_path = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/csvdataFULL/BCIML_Dataset/populatedGPPsMORN.csv\"\n",
    "#csv_master_path = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/csvdata10000/populatedGPPs.csv\"\n",
    "data_info = pd.read_csv(csv_master_path)\n",
    "GPP_arr = np.asarray(data_info.iloc[:,1])\n",
    "fig=plt.figure(figsize=(20.0, 5.0))\n",
    "plt.plot(GPP_arr)\n",
    "plt.ylabel('GPP')\n",
    "plt.title(\"GPP Changes Over Full Data Collection Period\")\n",
    "plt.figure(figsize=(20,5))\n",
    "os.chdir(r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2\")\n",
    "plt.show()\n",
    "os.chdir(csvdataLocation)\n",
    "\n",
    "my_dpi=96\n",
    "\n",
    "fig.savefig(graphTitle+' GPP Changes.png', dpi=my_dpi*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
