{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Takes GPP and date information from old master file and creates a new Machine Learning Master File\\n   With one column representing file names for the converted CSVs and the other column being their respective\\n   GPPs as pulled from the old master file or calculated with linear interpolation'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peter Karras 2020\n",
    "'''Takes GPP and date information from old master file and creates a new Machine Learning Master File\n",
    "   With one column representing file names for the converted CSVs and the other column being their respective\n",
    "   GPPs as pulled from the old master file or calculated with linear interpolation'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a string that represents name of csv file and \n",
    "# converts that string to one that matches the date string present\n",
    "# in the old master file (old master file refers to the raw excel file\n",
    "# filled with extraneous data from BCI)that contains the date/times \n",
    "# for recorded GPP values\n",
    "def change_csv_date(csv):\n",
    "    year = csv[2:4]\n",
    "    month = csv[5:7]\n",
    "    day = csv[8:10]\n",
    "    hour = csv[11:13]\n",
    "    minute = csv[14:16]\n",
    "    second = \"00\"\n",
    "    if(int(hour) == 0):\n",
    "        hour = \"0\"\n",
    "    elif(int(hour) < 10):\n",
    "        hour = hour[1:2]\n",
    "    # No leading zeroes in day or month\n",
    "    if(int(month) < 10):\n",
    "        month = month[1:2]\n",
    "    if(int(day) < 10):\n",
    "        day = day[1:2]\n",
    "    result = month + \"/\" + day + \"/\" + year + \" \" + hour + \":\" + minute #+ \":\" + second + \" \" + timeDay\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in csv date (in format 'YYYY_MM_DD_HH_MM_bci_t') and checks to see if minutes are divisble by div\n",
    "def check_csv_date(csv, div):\n",
    "    result = False\n",
    "    minute = int(csv[14:16])\n",
    "    remainder = minute % div\n",
    "    if(remainder == 0):\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(check_csv_date(\"2015_03_14_14_00_bci_t.csv\",30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015_06_29_04_00_bci_t.csv\n"
     ]
    }
   ],
   "source": [
    "# Grabs all GPP values and dates from master file (as defined above)\n",
    "masterfileLocation = r\"C:\\Users\\Peter\\Desktop\\Thermo_R_Code\\FinalThermo\\new2\"\n",
    "os.chdir(masterfileLocation)\n",
    "col_list = [\"date\", \"GPP\"]\n",
    "masterFileName = \"all-30min-Apr2018_working.csv\"\n",
    "dateGPPList = pd.read_csv(masterFileName, usecols=col_list) \n",
    "dateGPPList = dateGPPList.set_index(\"date\")\n",
    "\n",
    "\n",
    "\n",
    "csvdataLocation = r\"C:\\Users\\Peter\\Desktop\\Thermo_R_Code\\FinalThermo\\new2\\csvdata933\"\n",
    "(_, _, csvfiles) = next(os.walk(csvdataLocation))\n",
    "print(csvfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chunk of code matches the file names from the old master file to the\n",
    "# names gotten from the \"csvdata\" folder, so that each thermal csv file has it's\n",
    "# corresponding GPP value matched to it\n",
    "# NOTE: In addition to matching GPP values, this code also fills in GPP values\n",
    "# for those images without recorded values through linear interpoaltion\n",
    "# NOTE: Currently only works when first CSV is from a 30 min increment\n",
    "# NOTE: Anomolies in data make it so sometimes data moves in 1 minute increments, \n",
    "# currently this function cannot circumvents this and these files must be removed\n",
    "\n",
    "# NOTE: Still has issues when there is a gap within masterfile data, currently just files\n",
    "# intermeditate values with last known val for GPP\n",
    "\n",
    "dictList = list()\n",
    "\n",
    "counter = 0\n",
    "numLoops = len(csvfiles)\n",
    "oldGPP = -1.1\n",
    "for i in range(0, numLoops, 6):\n",
    "    #GPPDataDict.clear()\n",
    "    currFile = csvfiles[i]\n",
    "    adaptedDate = change_csv_date(currFile)\n",
    "    try:\n",
    "        currGPP = dateGPPList.at[adaptedDate,\"GPP\"]\n",
    "    except:\n",
    "        print(\"Gap in time: \", adaptedDate)\n",
    "    if(i == 0):\n",
    "        #GPPDataDict.update({currFile : currGPP})\n",
    "        GPPDataDict = dict()\n",
    "        GPPDataDict.update({\"GPP\" : currGPP})\n",
    "        GPPDataDict.update({\"FILE\" : currFile})\n",
    "        dictList.append(GPPDataDict)\n",
    "        oldGPP = currGPP\n",
    "        continue\n",
    "        \n",
    "    GPPDataDictTemp = dict()\n",
    "    GPPDataDictTemp.update({\"GPP\" : currGPP})\n",
    "    GPPDataDictTemp.update({\"FILE\" : currFile})\n",
    "    \n",
    "    \n",
    "    diffGPP = currGPP - oldGPP\n",
    "    increment = diffGPP / 6.0\n",
    "    for j in range(i-5, i, 1):\n",
    "        oldGPP += increment\n",
    "        currFile = csvfiles[j]\n",
    "        #print(\"Here\", currFile)\n",
    "        GPPDataDict = dict()\n",
    "        GPPDataDict.update({\"GPP\" : oldGPP})\n",
    "        GPPDataDict.update({\"FILE\" : currFile})\n",
    "        dictList.append(GPPDataDict)\n",
    "    dictList.append(GPPDataDictTemp)\n",
    "    oldGPP = currGPP + increment\n",
    "    oldGPP = currGPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This writes a NEW master file, with one column containing the\n",
    "# thermal csv file names, and the other column containing their\n",
    "# GPP values as determined from previous code. New file name is \n",
    "# determined by variable csv_file1\n",
    "\n",
    "import csv\n",
    "saveLocation = csvdataLocation\n",
    "os.chdir(saveLocation)\n",
    "csv_file1 = \"populatedGPPs.csv\"\n",
    "csv_columns = ['FILE','GPP']\n",
    "try:\n",
    "    with open(csv_file1, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in dictList:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
