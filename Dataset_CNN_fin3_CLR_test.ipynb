{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1632,
     "status": "ok",
     "timestamp": 1591470456379,
     "user": {
      "displayName": "Peter Karras",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8cD6ExyaOIfQ0DJPVpcMEP6z-_niPHYwBJiVh2A=s64",
      "userId": "18401168128338827169"
     },
     "user_tz": 240
    },
    "id": "F5mNCDuqMjMW",
    "outputId": "17997de3-3fc5-44d0-fb4c-ad70a394375b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Contains the Custom Dataset creation and the CNN\\n    NOTE: MUST HAVE FILE FROM MAKEMASTER PROGRAM PRIOR TO RUNNING'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peter Karras 2020\n",
    "''' Contains the Custom Dataset creation and the CNN\n",
    "    NOTE: MUST HAVE FILE FROM MAKEMASTER PROGRAM PRIOR TO RUNNING'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To train for 20 minutes use 11.072848268760174 epochs\n"
     ]
    }
   ],
   "source": [
    "#Time: 401.0922603607178s for 10,000 files\n",
    "#max is: 43.8977567043499\n",
    "#max is: 22.0574247607658\n",
    "# Time: 153.2100191116333 for 4,000 files\n",
    "# max is: 40.046902918943\n",
    "# max is: 22.0574247607658\n",
    "# Time: 98.4042558670044 for 2,500 files\n",
    "# max is: 40.508388402478\n",
    "# min is: 24.8413349715329\n",
    "# Time: 33.11633038520813 for 933 files\n",
    "# max is: 40.3920694022969\n",
    "# min is: 24.8413349715329\n",
    "# Time: for 9000 files\n",
    "# max is: 43.85429664867971\n",
    "# min is: 21.584069668121902\n",
    "\n",
    "# FULL 55000\n",
    "#Time taken (s): 45913.3\n",
    "#Max value is: 43.8977567043499\n",
    "#Min value is: 21.584069668121902\n",
    "\n",
    "# March\n",
    "#Time: 187.95090889930725\n",
    "#max is: 40.342822540551296\n",
    "#min is: 22.0574247607658\n",
    "# April\n",
    "# Time: 286.47614312171936\n",
    "# max is: 43.8977567043499\n",
    "# min is: 23.0867814341884\n",
    "# May\n",
    "# Time: 355.6945369243622\n",
    "# max is: 41.651975331159896\n",
    "# min is: 22.549667363426103\n",
    "# June\n",
    "# Time: 258.5124309062958\n",
    "# max is: 42.1865665374543\n",
    "# min is: 24.2563848704595\n",
    "# July\n",
    "# Time: 117.10082149505615\n",
    "# max is: 40.3920694022969\n",
    "# min is: 23.3752163703192\n",
    "# August\n",
    "# Time: 167.5036985874176\n",
    "# max is: 40.1815051816256\n",
    "# min is: 22.1157735577469\n",
    "# Sep\n",
    "# Time: 252.0023398399353\n",
    "# max is: 43.200494433666\n",
    "# min is: 21.9034323541466\n",
    "# Morn\n",
    "# Time: 542.1251473999982\n",
    "# max is: 43.8977567043499\n",
    "# min is: 22.0574247607658\n",
    "# Afternoon\n",
    "# Time: 136.8002856000021\n",
    "# max is: 43.235454379802796\n",
    "# min is: 22.014967836717897\n",
    "# Night 2-9\n",
    "#Time: 655.5211607999954\n",
    "#max is: 40.432346810251296\n",
    "#min is: 21.584069668121902\n",
    "# DAytime\n",
    "#Time: 1074.7459823999998\n",
    "#max is: 43.8977567043499\n",
    "#min is: 21.584069668121902\n",
    "\"\"\"\n",
    "epochinfotime\n",
    "\"\"\"\n",
    "# 3batchsize Epochs for 55,000 take 1446 s per epoch\n",
    "# Epochs for 10,000 files take 280 s per epoch\n",
    "# Epochs for 4,000 files take 101 s per epoch\n",
    "# Epochs for 2,500 files take 65 s per epoch\n",
    "# Epochs for 933 files take 24 s per epoch\n",
    "\n",
    "\"\"\" \n",
    "EPOCH TIME CALC\n",
    "\"\"\"\n",
    "fileSize = 4000\n",
    "minutesToTrain = 20\n",
    "secondsPerEpoch = (0.0287*(fileSize) - 6.4268)\n",
    "secondsToTrain = minutesToTrain * 60.0\n",
    "epochsToUse = secondsToTrain/secondsPerEpoch\n",
    "print(\"To train for\", minutesToTrain, \"minutes use\", epochsToUse, \"epochs\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjKURHC6MjMc"
   },
   "outputs": [],
   "source": [
    "\"\"\" IMPORT NEEDED MODULES \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset  # For custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1042,
     "status": "ok",
     "timestamp": 1591470467686,
     "user": {
      "displayName": "Peter Karras",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8cD6ExyaOIfQ0DJPVpcMEP6z-_niPHYwBJiVh2A=s64",
      "userId": "18401168128338827169"
     },
     "user_tz": 240
    },
    "id": "lBadNzhPvsZl",
    "outputId": "844e9a72-6b82-4750-d049-717cd53e8613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/\n"
     ]
    }
   ],
   "source": [
    "# Issues with directories, use this to reset cwd and then move into desired directory \n",
    "#os.chdir(\"/content\")\n",
    "startingDir = os.getcwd()\n",
    "if startingDir != r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/\":\n",
    "    startingDir = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/\"\n",
    "print(startingDir)\n",
    "csvfilesMLLocation = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/csvdataFULL/BCIML_Dataset\"\n",
    "baseSaveLocation = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new/BCI-ML/Monthly_Data_Summaries_csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcFs2C-GMjMf"
   },
   "outputs": [],
   "source": [
    "\"\"\" CREATE CUSTOM DATASET \"\"\"\n",
    "# Pulls from pool of 900 thermal images\n",
    "class BCIDataset2(Dataset):\n",
    "    def __init__(self, csv_master_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_master_path (string): path to csv file with thermal image (csv's) file paths\n",
    "            as first column and GPP values as the second column, rows are one set of\n",
    "            correlating data points\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        # Transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        # Read the csv file \n",
    "        #self.data_info = pd.read_csv(csv_master_path, header=None)\n",
    "        self.data_info = pd.read_csv(csv_master_path)\n",
    "        # First column contains thermal image (csv's) file paths\n",
    "        self.thermal_path_arr = np.asarray(self.data_info.iloc[:,0])\n",
    "        # Second column is the GPP values for the images from first column\n",
    "        self.GPP_arr = np.asarray(self.data_info.iloc[:,1])        \n",
    "        self.transform = transforms.ToTensor()\n",
    "        max_list = np.full(1,-10)\n",
    "        min_list = np.full(1, 99999)\n",
    "        os.chdir(csvfilesMLLocation)\n",
    "        start = time.perf_counter()\n",
    "#         for filename in self.thermal_path_arr:\n",
    "#             file_temps = pd.read_csv(filename)\n",
    "#             file_temps_vals = file_temps.values\n",
    "#             torch_temps = torch.from_numpy(file_temps_vals)\n",
    "#             max_list = np.append(max_list, [torch.max(torch_temps)])\n",
    "#             min_list = np.append(min_list, [torch.min(torch_temps)])\n",
    "#         self.ABS_MAX = (torch.max(torch.from_numpy(max_list))).item()\n",
    "#         self.ABS_MIN = (torch.min(torch.from_numpy(min_list))).item()\n",
    "        self.ABS_MAX = 43.8977567043499\n",
    "        self.ABS_MIN = 21.584069668121902\n",
    "        print(f'Time: {time.perf_counter()-start}')\n",
    "        print(\"max is:\", self.ABS_MAX)\n",
    "        print(\"min is:\", self.ABS_MIN)\n",
    "            \n",
    "        \n",
    "    #NOTE: might need to flip image\n",
    "    def __getitem__(self, index):\n",
    "        # Get thermal image (csv) path\n",
    "        single_thermal_path = self.thermal_path_arr[index]\n",
    "        # Convert csv to pandas dataframe\n",
    "        pd_thermal_img = pd.read_csv(single_thermal_path)\n",
    "        # Convert pandas dataframe to numpy array\n",
    "        ###np_thermal_img = np.asarray(pd_thermal_img.iloc[:,1:])\n",
    "        np_thermal_img = np.asarray(pd_thermal_img)\n",
    "        # Normalization of values from orignal csv file, translates thermal values to 0-1 range\n",
    "        # https://stats.stackexchange.com/questions/70801/how-to-normalize-data-to-0-1-range\n",
    "        np_normalized_temp_no_channel = ((np_thermal_img-self.ABS_MIN)/(self.ABS_MAX - self.ABS_MIN))\n",
    "        # Flip image by 90 degrees, is commented out currently as might mess with network architecture\n",
    "        #np_thermal_img = np.rot90(np_thermal_img)\n",
    "        # Add num channels dimension and format correctly\n",
    "        np_normalized_temp = np.expand_dims(np_normalized_temp_no_channel, axis=0)\n",
    "        # Transform numpy array to tensor\n",
    "        tensor_normal_thermal_vals = torch.from_numpy(np_normalized_temp)\n",
    "        # Get GPP value for image\n",
    "        single_image_GPP = self.GPP_arr[index]\n",
    "        return(tensor_normal_thermal_vals, single_image_GPP, single_thermal_path)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Working network\"\"\"\n",
    "class BCIModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCIModel, self).__init__()\n",
    "        # Convulutional Layer 1 (sees 320 x 240 x 1 image tensor)\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding = 1)\n",
    "        # Convulutional Layer 2 (sees 160 x 120 x 16 image tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
    "        # Convulutional Layer 3 (sees 80 x 60 x 32 tensor, reduced height and width from max pooling layer and stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        # Convulutional Layer 4 (sees 40 x 30 x 64 tensor, reduced height and width from max pooling layer and stride=2)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3, padding = 1)\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        # Linear and Batchnorm Layers\n",
    "        self.fc1 = nn.Linear(128 * 20 * 15, 100)\n",
    "        self.BatchN = nn.BatchNorm1d(100)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "        \n",
    "        # Dropout Layer\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Add sequence of convulutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 128 * 20 * 15)\n",
    "        # Add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # Add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # Add last layer\n",
    "        x = (self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mIX8CIzRMjMi",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1.2000000424450263e-06\n",
      "max is: 43.8977567043499\n",
      "min is: 21.584069668121902\n",
      "BCIModel(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=38400, out_features=100, bias=True)\n",
      "  (BatchN): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n",
      "CUDA is available!  Training on GPU ...\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "GeForce RTX 2070 SUPER\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "Epoch #: 1\n",
      "Epoch: 1 \tTraining Loss: 32.396535 \tValidation Loss: 24.355655\n",
      "Validation loss decreased (inf --> 24.355655).  Saving model ...\n",
      "Time: 99.80916020000018\n",
      "Current Time = 14:46:43\n",
      "LR: 0.001\n",
      "Epoch #: 2\n",
      "Epoch: 2 \tTraining Loss: 24.612121 \tValidation Loss: 17.204533\n",
      "Validation loss decreased (24.355655 --> 17.204533).  Saving model ...\n",
      "Time: 96.41738200000009\n",
      "Current Time = 14:48:20\n",
      "LR: 0.001\n",
      "Epoch #: 3\n",
      "Epoch: 3 \tTraining Loss: 20.179743 \tValidation Loss: 18.273575\n",
      "Time: 96.35632709999982\n",
      "Current Time = 14:49:56\n",
      "LR: 0.001\n",
      "Epoch #: 4\n",
      "Epoch: 4 \tTraining Loss: 17.385593 \tValidation Loss: 13.963910\n",
      "Validation loss decreased (17.204533 --> 13.963910).  Saving model ...\n",
      "Time: 95.81350030000021\n",
      "Current Time = 14:51:32\n",
      "LR: 0.001\n",
      "Epoch #: 5\n",
      "Epoch: 5 \tTraining Loss: 14.526151 \tValidation Loss: 9.917360\n",
      "Validation loss decreased (13.963910 --> 9.917360).  Saving model ...\n",
      "Time: 101.72345309999992\n",
      "Current Time = 14:53:14\n",
      "LR: 0.001\n",
      "Epoch #: 6\n",
      "Epoch: 6 \tTraining Loss: 12.812063 \tValidation Loss: 11.015376\n",
      "Time: 96.49837190000017\n",
      "Current Time = 14:54:50\n",
      "LR: 0.001\n",
      "Operation Complete\n",
      "training_data_4000.csv\n",
      "C:\\Users\\Peter\\Desktop\\Thermo_R_Code\\FinalThermo\\new2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x72 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from 0 : 1.1164699792861938\n",
      "Output of network:\t tensor([ 0.2252,  0.1738,  0.1738,  0.1738,  0.5491, 17.8174], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  2.7357, 19.1503], device='cuda:0') \n",
      "\n",
      "1.1164699792861938\n",
      "test loss from 1 : 3.920398712158203\n",
      "Output of network:\t tensor([ 0.3007, 11.3446, 11.2693,  9.3210,  0.2525, 13.3368], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 1.8804, 11.9150, 14.2394, 12.3979,  0.0000, 14.8695], device='cuda:0') \n",
      "\n",
      "3.920398712158203\n",
      "test loss from 2 : 17.762266159057617\n",
      "Output of network:\t tensor([ 0.4570, 16.2283,  0.3882, 15.1440, 13.5807, 11.3669], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 19.2888,  0.0000, 20.7424, 14.6478, 19.3897], device='cuda:0') \n",
      "\n",
      "17.762266159057617\n",
      "test loss from 3 : 40.46855163574219\n",
      "Output of network:\t tensor([ 2.8585, 10.1358,  0.3613, 15.4406,  6.4585,  0.3887], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 1.7883, 24.7843,  0.0000, 18.5061,  2.2863,  0.0000], device='cuda:0') \n",
      "\n",
      "40.46855163574219\n",
      "test loss from 4 : 72.5919418334961\n",
      "Output of network:\t tensor([0.1738, 0.4067, 0.1738, 0.4722, 8.7863, 3.9079], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  0.0000,  0.0000, 17.2972, 22.9518], device='cuda:0') \n",
      "\n",
      "72.5919418334961\n",
      "test loss from 5 : 11.720136642456055\n",
      "Output of network:\t tensor([ 0.2187, 13.2970, 15.5917,  0.1738,  0.3315,  0.1738], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 15.2077, 18.9814,  0.0000,  7.7525,  0.0000], device='cuda:0') \n",
      "\n",
      "11.720136642456055\n",
      "test loss from 6 : 17.014625549316406\n",
      "Output of network:\t tensor([12.2208, 16.4484,  0.1738, 15.9746,  2.8187,  0.5083], device='cuda:0')\n",
      "Target Values:\t\t tensor([14.7018, 20.1621,  0.0000, 18.0341, 11.6283,  0.0000], device='cuda:0') \n",
      "\n",
      "17.014625549316406\n",
      "test loss from 7 : 10.854883193969727\n",
      "Output of network:\t tensor([ 1.8999,  0.3361,  5.6742,  0.1738, 13.2339, 14.4154], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 5.7463,  0.0000,  8.4659,  0.0000, 13.9714, 20.8849], device='cuda:0') \n",
      "\n",
      "10.854883193969727\n",
      "test loss from 8 : 3.0708465576171875\n",
      "Output of network:\t tensor([14.8633,  6.0011,  1.5369, 19.2912,  0.3665,  8.6183], device='cuda:0')\n",
      "Target Values:\t\t tensor([16.3632,  4.0710,  4.0391, 21.7515,  0.0000,  8.5774], device='cuda:0') \n",
      "\n",
      "3.0708465576171875\n",
      "test loss from 9 : 2.4811818599700928\n",
      "Output of network:\t tensor([15.9291,  0.3990,  0.1738,  0.5096, 16.4187,  0.1738], device='cuda:0')\n",
      "Target Values:\t\t tensor([15.9241,  0.0000,  0.0000,  3.1318, 19.2101,  0.0000], device='cuda:0') \n",
      "\n",
      "2.4811818599700928\n",
      "16.59932518005371\n",
      "12.31815242767334\n",
      "25.120807647705078\n",
      "0.7965644598007202\n",
      "4.743457317352295\n",
      "28.601055145263672\n",
      "28.24995231628418\n",
      "11.169272422790527\n",
      "0.07950682938098907\n",
      "3.138460874557495\n",
      "11.563041687011719\n",
      "4.688793182373047\n",
      "21.6978816986084\n",
      "3.7805728912353516\n",
      "9.645769119262695\n",
      "45.77637481689453\n",
      "20.000553131103516\n",
      "7.278659343719482\n",
      "3.4124298095703125\n",
      "33.428184509277344\n",
      "5.5612030029296875\n",
      "0.9495862722396851\n",
      "43.109825134277344\n",
      "2.7183148860931396\n",
      "4.11389684677124\n",
      "3.4863758087158203\n",
      "26.87677764892578\n",
      "13.457529067993164\n",
      "1.7982912063598633\n",
      "5.784431457519531\n",
      "18.052703857421875\n",
      "4.062905788421631\n",
      "3.593230724334717\n",
      "2.9320554733276367\n",
      "1.3006987571716309\n",
      "31.73493766784668\n",
      "11.014982223510742\n",
      "4.8412370681762695\n",
      "1.141053318977356\n",
      "6.248044013977051\n",
      "8.401082992553711\n",
      "24.012968063354492\n",
      "4.803791046142578\n",
      "1.802605390548706\n",
      "2.000950574874878\n",
      "1.6686586141586304\n",
      "1.3070727586746216\n",
      "2.308983325958252\n",
      "4.296694755554199\n",
      "2.0625040531158447\n",
      "3.6680736541748047\n",
      "39.8509521484375\n",
      "2.1795992851257324\n",
      "8.821545600891113\n",
      "8.496219635009766\n",
      "5.483640193939209\n",
      "21.17226791381836\n",
      "0.27172353863716125\n",
      "11.000030517578125\n",
      "2.4519248008728027\n",
      "16.62594223022461\n",
      "0.6257035732269287\n",
      "15.918429374694824\n",
      "27.314077377319336\n",
      "0.29188549518585205\n",
      "1.1594796180725098\n",
      "6.116252422332764\n",
      "6.384499549865723\n",
      "9.919336318969727\n",
      "7.95460319519043\n",
      "9.204591751098633\n",
      "9.419242858886719\n",
      "28.713573455810547\n",
      "4.497863292694092\n",
      "15.554423332214355\n",
      "8.187726974487305\n",
      "0.8575291037559509\n",
      "6.7862982749938965\n",
      "17.017953872680664\n",
      "3.11714506149292\n",
      "19.262746810913086\n",
      "8.212759971618652\n",
      "11.294173240661621\n",
      "8.182723045349121\n",
      "2.6767916679382324\n",
      "0.9843709468841553\n",
      "10.671381950378418\n",
      "5.139211177825928\n",
      "2.3339364528656006\n",
      "~~~~~~~~~~~~~~~~~~~~~~~\n",
      "tset before divide: 1086.354138419032\n",
      "~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~\n",
      "len test sampler: 590\n",
      "~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Loss (mean squared error): 11.047669\n",
      "\n",
      "Time: 19.558381599999848\n",
      "training_data_4000.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#################################\n",
    "\n",
    "NEW NETWORK CREATION/TRAINING\n",
    "\n",
    "#################################\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "month_list = [\"4000\"]\n",
    "batch_size = 6\n",
    "# For training\n",
    "n_epochs = 6\n",
    "\n",
    "\n",
    "for MONTH_NAME in month_list:\n",
    "    \"\"\" \n",
    "\n",
    "        LOAD IN DATA \n",
    "\n",
    "    \"\"\"\n",
    "    month = MONTH_NAME\n",
    "    os.chdir(startingDir)\n",
    "    # Number of subprocesses to use for data loading\n",
    "    # Using advice of 4 workers per GPU\n",
    "    # Getting errors with any # of workers > 0\n",
    "    num_workers = 0\n",
    "\n",
    "    # Proportion of training set to use for validation and testing\n",
    "    # Note: this will be split in equal halves, one for validation, one for testing\n",
    "    valid_and_test_proportion = 0.3\n",
    "\n",
    "\n",
    "    # Define transforms\n",
    "    transformations = transforms.Compose([transforms.ToTensor()])\n",
    "    # Define custom datasets, for training and for testing\n",
    "    # Note: Will be using 10,000 data for testing, 50,000 data for training in future\n",
    "    masterfileMLLocation = csvfilesMLLocation + r\"/populatedGPPs\" + month + \".csv\"\n",
    "    BCIDataset = BCIDataset2(masterfileMLLocation)\n",
    "\n",
    "    # Obtain indices for training, validation and testing datasets\n",
    "    num_train = len(BCIDataset)         # Number of data points (csv files to be used)\n",
    "    indices1 = list(range(num_train))   # indices of [0,num_train) to represent data\n",
    "    np.random.shuffle(indices1)         # Shuffled indices\n",
    "    # Splitting training from validation/testing\n",
    "    split1 = int(np.floor(valid_and_test_proportion * num_train))\n",
    "\n",
    "    train_indices, valid_and_test_indices = indices1[split1:], indices1[:split1]\n",
    "    # Splitting validation/testing up into their individual groups\n",
    "    num_valid_test = len(valid_and_test_indices)\n",
    "\n",
    "    split2 = int(np.floor(0.5 * num_valid_test))\n",
    "    valid_indices, test_indices = valid_and_test_indices[split2:], valid_and_test_indices[:split2]\n",
    "\n",
    "    baseSaveLocation = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new/BCI-ML/Monthly_Data_Summaries_csv\"\n",
    "    os.chdir(baseSaveLocation)\n",
    "    random.seed()\n",
    "    idNum = str(random.randint(1,9999999))\n",
    "    summaryInfoDir = month+\"_new\"+idNum\n",
    "    os.mkdir(summaryInfoDir)\n",
    "    # SAVE Indices in case further training is needed, dont want to overfit the data for future retrains\n",
    "    os.chdir(baseSaveLocation+\"/\"+summaryInfoDir)\n",
    "    titlesIndicesData = [\"train_indices\",\"valid_indices\",\"test_indices\"]\n",
    "    indicesFile = \"indices_data_\" + month +\".csv\"\n",
    "    with open(indicesFile,'w',newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(titlesIndicesData)\n",
    "        counter = 0\n",
    "        for train in train_indices:\n",
    "            if counter >= len(test_indices): \n",
    "                test = -1\n",
    "            else:\n",
    "                test = test_indices[counter]\n",
    "            if counter >= len(valid_indices): \n",
    "                valid = -1\n",
    "            else:\n",
    "                valid = valid_indices[counter]\n",
    "            counter = counter + 1\n",
    "            writer.writerow([train,valid,test])\n",
    "    os.chdir(startingDir)\n",
    "    \n",
    "    # Define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "        Batch Making\n",
    "\n",
    "    \"\"\"\n",
    "    # Prepare data loaders \n",
    "    train_loader = torch.utils.data.DataLoader(BCIDataset, batch_size=batch_size,\n",
    "                                               sampler=train_sampler, num_workers=num_workers, pin_memory=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(BCIDataset, batch_size=batch_size,\n",
    "                                               sampler=valid_sampler, num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(BCIDataset, batch_size=batch_size,\n",
    "                                               sampler=test_sampler, num_workers=num_workers, pin_memory=True)\n",
    "    \"\"\"\n",
    "\n",
    "        Initialize model, optimizer, LR schedueler\n",
    "\n",
    "    \"\"\"\n",
    "    # Initialize model\n",
    "    model = BCIModel()\n",
    "    # defining the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr =0.001)\n",
    "    # defining the scheduler, to handle learning rate changes\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.98)\n",
    "    #scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr = 0.002, max_lr=0.012,cycle_momentum=False,step_size_up=100)\n",
    "\n",
    "    # defining loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    print(model)\n",
    "    # check if CUDA is available\n",
    "    train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "    if not train_on_gpu:\n",
    "        print('CUDA is not available.  Training on CPU ...')\n",
    "    else:\n",
    "        print('CUDA is available!  Training on GPU ...')\n",
    "        model.cuda()\n",
    "\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    # Optimization? Best for inputs that do not change in size (this network)\n",
    "    # \"This flag allows you to enable the inbuilt cudnn auto-tuner to find the best algorithm to use for your hardware\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # Check that we are on GPU\n",
    "    for p in model.parameters():\n",
    "        print(p.device)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "    \n",
    "    \"\"\" TRAINING OF MODEL \"\"\"\n",
    "    os.chdir(startingDir)\n",
    "    valid_loss_min = np.Inf \n",
    "    #csvfilesMLLocation = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/csvdata10000\"\n",
    "    os.chdir(csvfilesMLLocation)\n",
    "    # Number of epochs to train the model\n",
    "    # try 10, 100, 500, 1000\n",
    "    test_loss = 0.0\n",
    "\n",
    "    train_loss_vals = []\n",
    "    valid_loss_vals = []\n",
    "    epochCounter = []\n",
    "    lr_vals = []\n",
    "    time_taken_vals = []\n",
    "    os.chdir(csvfilesMLLocation)\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        epochCounter.append(epoch)\n",
    "        lr_vals.append(optimizer.param_groups[0]['lr'])    \n",
    "        # Measurement of epoch times\n",
    "        start = time.perf_counter()\n",
    "        print(\"Epoch #:\", epoch)\n",
    "        # Keep track of training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        os.chdir(csvfilesMLLocation)\n",
    "        for data, target, _ in train_loader:\n",
    "            data, target = data.float(), target.float()\n",
    "            # Move tensors to GPU if CUDA is available\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # Clear the gradients fo all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # Fixes shape\n",
    "            output = torch.flatten(output)\n",
    "            # Calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            # Perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # Update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for data, target, _ in valid_loader:\n",
    "            data, target = data.float(), target.float()\n",
    "            # Move tensors to GPU if CUDA is available\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # Fixes shape\n",
    "            output = torch.flatten(output)\n",
    "            # Calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # Update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # Calculate avearage losses\n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        # Update validation loss list\n",
    "        valid_loss_vals.append(valid_loss)\n",
    "        # Update training loss list\n",
    "        train_loss_vals.append(train_loss)\n",
    "\n",
    "        # Print training/validation stats\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, train_loss, valid_loss))\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            valid_loss_str =(str(valid_loss)).replace(\".\",\"-\")\n",
    "            os.chdir(baseSaveLocation+\"/\"+summaryInfoDir)\n",
    "            torch.save(model.state_dict(), 'model_BCI_' + month + \"_\" + valid_loss_str + '.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "        # save model no matter performance\n",
    "        os.chdir(baseSaveLocation+\"/\"+summaryInfoDir)\n",
    "        torch.save(model.state_dict(), 'model_BCI_unoptim_' + month + '.pt')\n",
    "        os.chdir(csvfilesMLLocation)\n",
    "\n",
    "        # End of time check\n",
    "        print(f'Time: {time.perf_counter()-start}')\n",
    "        time_taken_vals.append(time.perf_counter()-start)\n",
    "        # Time of completion\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(\"Current Time =\", current_time)\n",
    "        print(\"LR:\",optimizer.param_groups[0]['lr'])        \n",
    "        if epoch >= 40:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "    print(\"Operation Complete\")\n",
    "    \n",
    "    '''\n",
    "    Save training data and stats\n",
    "    '''\n",
    "    \n",
    "    os.chdir(baseSaveLocation+\"/\"+summaryInfoDir)\n",
    "    \n",
    "    file1 = open(\"stats_\"+MONTH_NAME+\"_\"+idNum+\".txt\",\"a\")\n",
    "    file1.write(\"Epochs: \" + str(n_epochs) +\"\\n\")\n",
    "    file1.write(\"Batch Size: \" + str(batch_size))\n",
    "    file1.close()\n",
    "    \n",
    "    titlesTrainingData = [\"epoch\",\"train_loss\",\"valid_loss\",\"learning_rate\",\"time_taken\"]\n",
    "    trainFileStats = \"training_data_\" + month +\".csv\"\n",
    "    print(trainFileStats)\n",
    "    with open(trainFileStats,'w',newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(titlesTrainingData)\n",
    "        for epoch, train, valid, lr, time_t in zip(epochCounter, train_loss_vals, valid_loss_vals, lr_vals, time_taken_vals):\n",
    "            writer.writerow([epoch,train,valid,lr,time_t])\n",
    "    os.chdir(startingDir)\n",
    "\n",
    "    \"\"\" \n",
    "    CREATION OF TEST RANGE LR PLOT\n",
    "    \"\"\"\n",
    "    fig2=plt.figure(figsize=(10.0, 5.0))\n",
    "    print(os.getcwd())\n",
    "    plt.scatter(epochCounter, lr_vals, c=\"blue\")\n",
    "    plt.plot(epochCounter, lr_vals, c=\"blue\")\n",
    "    #plt.xlim(0,0.05)\n",
    "    # plt.ylim(0,100)\n",
    "    plt.xlabel(\"Learning Rate\", fontweight=\"semibold\")\n",
    "    plt.ylabel(\"Training Accuracy\", fontweight=\"semibold\")\n",
    "    plt.title(\"LR Changes Plot \"+month, fontweight=\"bold\")\n",
    "    plt.figure(figsize=(15,1))\n",
    "    plt.show()\n",
    "    my_dpi=96\n",
    "    os.chdir(baseSaveLocation+\"/\"+summaryInfoDir)\n",
    "    fig2.savefig(\"LR Changes \"+month,dpi=my_dpi*5)\n",
    "    os.chdir(startingDir)\n",
    "    \n",
    "\n",
    "    \"\"\" \n",
    "    TESTING OF MODEL \n",
    "    \"\"\"\n",
    "    # Print out values and images that have large differences in target/value\n",
    "\n",
    "    # Track test loss\n",
    "    test_loss = 0.0\n",
    "    num_predictions = len(test_indices)\n",
    "    #import time\n",
    "    # Puts model will notify all your layers that you are in eval mode, that way, \n",
    "    # batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "    model.eval()\n",
    "    tarList = list()\n",
    "    outList = list()\n",
    "    fileList= list()\n",
    "    start = time.perf_counter()\n",
    "    counter = 0\n",
    "    os.chdir(csvfilesMLLocation)\n",
    "    # Iterate over test data\n",
    "    with torch.no_grad():\n",
    "        for data, target, file_names in test_loader:\n",
    "            data, target = data.float(), target.float()\n",
    "            # Move tensors to GPU if CUDA is available\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            output = torch.flatten(output)\n",
    "            # Calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # Update test loss \n",
    "            test_loss += loss.item()\n",
    "\n",
    "            for tar, out, file in zip(target, output, file_names):\n",
    "                tarList.append(tar.item())\n",
    "                outList.append(out.item())\n",
    "                fileList.append(file)\n",
    "\n",
    "            if counter < 10:\n",
    "                print(\"test loss from\", counter, \":\", loss.item())\n",
    "                print(\"Output of network:\\t\", output)\n",
    "                print(\"Target Values:\\t\\t\", target,\"\\n\")\n",
    "\n",
    "            # Example data tensors\n",
    "            if counter < 200000:\n",
    "                #print(\"loss from this run:\", loss.item())\n",
    "                print(loss.item())\n",
    "                #print(\"Output of network:\\t\", output)\n",
    "                counterTHIS = 0\n",
    "                for value in output:\n",
    "                    counterTHIS += 1\n",
    "                    #print(\"Output\", counterTHIS, \":\", value.item())\n",
    "                counterTHIS = 0\n",
    "                for value in target:\n",
    "                    counterTHIS += 1\n",
    "                    #print(\"Target\", counterTHIS, \":\", value.item())\n",
    "                #print(\"Target Values:\\t\", target,\"\\n\")\n",
    "                counter += 1\n",
    "                # CHECK LOss HEEWRE\n",
    "\n",
    "\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        print(\"tset before divide:\",test_loss)\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        test_loss = test_loss/(len(test_loader.sampler)/batch_size)\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        print(\"len test sampler:\",len(test_loader.sampler))\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        print('Test Loss (mean squared error): {:.6f}\\n'.format(test_loss))\n",
    "    print(f'Time: {time.perf_counter()-start}')\n",
    "\n",
    "    \n",
    "    os.chdir(baseSaveLocation+\"/\"+summaryInfoDir)\n",
    "    titlesTestData = [\"targets\",\"outputs\",\"filename\"]\n",
    "    test_loss_str =(str(test_loss)).replace(\".\",\"-\")\n",
    "    testFileStats = \"test_data_\" + month + \"_\"+ test_loss_str +\".csv\"\n",
    "    print(trainFileStats)\n",
    "    with open(testFileStats,'w',newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(titlesTestData)\n",
    "        for target, output, file in zip(tarList, outList, fileList):\n",
    "            writer.writerow([target,output,file])\n",
    "    os.chdir(startingDir)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Dataset_CNN_fin2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
