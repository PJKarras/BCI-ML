{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Takes GPP and date information from old master file and creates a new Machine Learning Master File\\n   With one column representing file names for the converted CSVs and the other column being their respective\\n   GPPs as pulled from the old master file or calculated with linear interpolation'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peter Karras 2020\n",
    "'''Takes GPP and date information from old master file and creates a new Machine Learning Master File\n",
    "   With one column representing file names for the converted CSVs and the other column being their respective\n",
    "   GPPs as pulled from the old master file or calculated with linear interpolation'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a string that represents name of csv file and \n",
    "# converts that string to one that matches the date string present\n",
    "# in the old master file (old master file refers to the raw excel file\n",
    "# filled with extraneous data from BCI)that contains the date/times \n",
    "# for recorded GPP values\n",
    "def change_csv_date(csv):\n",
    "    year = csv[2:4]\n",
    "    month = csv[5:7]\n",
    "    day = csv[8:10]\n",
    "    hour = csv[11:13]\n",
    "    minute = csv[14:16]\n",
    "    second = \"00\"\n",
    "    if(int(hour) == 0):\n",
    "        hour = \"0\"\n",
    "    elif(int(hour) < 10):\n",
    "        hour = hour[1:2]\n",
    "    # No leading zeroes in day or month\n",
    "    if(int(month) < 10):\n",
    "        month = month[1:2]\n",
    "    if(int(day) < 10):\n",
    "        day = day[1:2]\n",
    "    result = month + \"/\" + day + \"/\" + year + \" \" + hour + \":\" + minute #+ \":\" + second + \" \" + timeDay\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015_03_14_13_30_bci_t.csv\n"
     ]
    }
   ],
   "source": [
    "# Grabs all GPP values and dates from master file (as defined above)\n",
    "masterfileLocation = r\"C:\\Users\\Peter\\Desktop\\Thermo_R_Code\\FinalThermo\"\n",
    "os.chdir(masterfileLocation)\n",
    "col_list = [\"date\", \"GPP\"]\n",
    "masterFileName = \"all-30min-Apr2018_working.csv\"\n",
    "dateGPPList = pd.read_csv(masterFileName, usecols=col_list) \n",
    "dateGPPList = dateGPPList.set_index(\"date\")\n",
    "\n",
    "# This looks at local files using getcwd (get current working directory) \n",
    "# and will look into a folder named \"csvdata\" (no quotes) and grab the file \n",
    "# names of all the files that have been made into CSV's from the original\n",
    "# .seq files using the R conversion program in that \"csvdata\" folder \n",
    "\n",
    "# csvdataLocation = r\"C:\\Users\\Peter\\Desktop\\Thermo_R_Code\\FinalThermo\\csvdata\"\n",
    "# os.chdir(csvdataLocation)\n",
    "# csvfiles = [os.path.abspath(x) for x in os.listdir()]\n",
    "\n",
    "csvdataLocation = r\"C:\\Users\\Peter\\Desktop\\Thermo_R_Code\\FinalThermo\\csvdata\"\n",
    "(_, _, csvfiles) = next(os.walk(csvdataLocation))\n",
    "print(csvfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/14/15 13:30\n",
      "3/14/15 14:00\n",
      "3/14/15 14:30\n",
      "3/14/15 15:00\n",
      "3/14/15 15:30\n",
      "3/14/15 16:00\n",
      "3/14/15 16:30\n",
      "3/14/15 17:00\n",
      "3/14/15 17:30\n",
      "3/14/15 18:00\n",
      "3/14/15 18:30\n",
      "3/14/15 19:00\n",
      "3/14/15 19:30\n",
      "3/14/15 20:00\n",
      "3/14/15 20:30\n",
      "3/14/15 21:00\n",
      "3/14/15 21:30\n",
      "3/14/15 22:00\n",
      "3/14/15 22:30\n",
      "3/14/15 23:00\n",
      "3/14/15 23:30\n",
      "3/15/15 0:00\n",
      "3/15/15 0:30\n",
      "3/15/15 1:00\n",
      "3/15/15 1:30\n",
      "3/15/15 2:00\n",
      "3/15/15 2:30\n",
      "3/15/15 3:00\n",
      "3/15/15 3:30\n",
      "3/15/15 4:00\n",
      "3/15/15 4:30\n",
      "3/15/15 5:00\n",
      "3/15/15 5:30\n",
      "3/15/15 6:00\n",
      "3/15/15 6:30\n",
      "3/15/15 7:00\n",
      "3/15/15 7:30\n",
      "3/15/15 8:00\n",
      "3/15/15 8:30\n",
      "3/15/15 9:00\n",
      "3/15/15 9:30\n",
      "3/15/15 10:00\n",
      "3/15/15 10:30\n",
      "3/15/15 11:00\n",
      "3/15/15 11:30\n",
      "3/15/15 12:00\n",
      "3/15/15 12:30\n",
      "3/15/15 13:00\n",
      "3/15/15 13:30\n",
      "3/15/15 14:00\n",
      "3/15/15 14:30\n",
      "3/15/15 15:00\n",
      "3/15/15 15:30\n",
      "3/15/15 16:00\n",
      "3/15/15 16:30\n",
      "3/15/15 17:00\n",
      "3/15/15 17:30\n",
      "3/15/15 18:00\n",
      "3/15/15 18:30\n",
      "3/15/15 19:00\n",
      "3/15/15 19:30\n",
      "3/15/15 20:00\n",
      "3/15/15 20:30\n",
      "3/15/15 21:00\n",
      "3/15/15 21:30\n",
      "3/15/15 22:00\n",
      "3/15/15 22:30\n",
      "3/15/15 23:00\n",
      "3/15/15 23:30\n",
      "3/16/15 0:00\n",
      "3/16/15 0:30\n",
      "3/16/15 1:00\n",
      "3/16/15 1:30\n",
      "3/16/15 2:00\n",
      "3/16/15 2:30\n",
      "3/16/15 3:00\n",
      "3/16/15 3:30\n",
      "3/16/15 4:00\n",
      "3/16/15 4:30\n",
      "3/16/15 5:00\n",
      "3/16/15 5:30\n",
      "3/16/15 6:00\n",
      "3/16/15 6:30\n",
      "3/16/15 7:00\n",
      "3/16/15 7:30\n",
      "3/16/15 8:00\n",
      "3/16/15 8:30\n",
      "3/16/15 9:00\n",
      "3/16/15 9:30\n",
      "3/16/15 10:00\n",
      "3/16/15 10:30\n",
      "3/16/15 11:00\n",
      "3/16/15 11:30\n",
      "3/16/15 12:00\n",
      "3/16/15 12:30\n",
      "3/16/15 13:00\n",
      "3/16/15 13:30\n",
      "3/16/15 14:00\n",
      "3/16/15 14:30\n",
      "3/16/15 15:00\n",
      "3/16/15 15:30\n",
      "3/16/15 16:00\n",
      "3/16/15 16:30\n",
      "3/16/15 17:00\n",
      "3/16/15 17:30\n",
      "3/16/15 18:00\n",
      "3/16/15 18:30\n",
      "3/16/15 19:00\n",
      "3/16/15 19:30\n",
      "3/16/15 20:00\n",
      "3/16/15 20:30\n",
      "3/16/15 21:00\n",
      "3/16/15 21:30\n",
      "3/16/15 22:00\n",
      "3/16/15 22:30\n",
      "3/16/15 23:00\n",
      "3/16/15 23:30\n",
      "3/17/15 0:00\n",
      "3/17/15 0:30\n",
      "3/17/15 1:00\n",
      "3/17/15 1:30\n",
      "3/17/15 2:00\n",
      "3/17/15 2:30\n",
      "3/17/15 3:00\n",
      "3/17/15 3:30\n",
      "3/17/15 4:00\n",
      "3/17/15 4:30\n",
      "3/17/15 5:00\n",
      "3/17/15 5:30\n",
      "3/17/15 6:00\n",
      "3/17/15 6:30\n",
      "3/17/15 7:00\n",
      "3/17/15 7:30\n",
      "3/17/15 8:00\n",
      "3/17/15 8:30\n",
      "3/17/15 9:00\n",
      "3/17/15 9:30\n",
      "3/17/15 10:00\n",
      "3/17/15 10:30\n",
      "3/17/15 11:00\n",
      "3/17/15 11:30\n",
      "3/17/15 12:00\n",
      "3/17/15 12:30\n",
      "3/17/15 13:00\n",
      "3/17/15 13:30\n",
      "3/17/15 14:00\n",
      "3/17/15 14:30\n",
      "3/17/15 15:00\n",
      "3/17/15 15:30\n",
      "3/17/15 16:00\n",
      "3/17/15 16:30\n",
      "3/17/15 17:00\n",
      "3/17/15 17:30\n",
      "3/17/15 18:00\n",
      "3/17/15 18:30\n",
      "3/17/15 19:00\n",
      "3/17/15 19:30\n",
      "3/17/15 20:00\n",
      "3/17/15 20:30\n",
      "3/17/15 21:00\n",
      "3/17/15 21:30\n",
      "3/17/15 22:00\n",
      "3/17/15 22:30\n",
      "3/17/15 23:00\n",
      "3/17/15 23:30\n",
      "3/18/15 0:00\n"
     ]
    }
   ],
   "source": [
    "# This chunk of code matches the file names from the old master file to the\n",
    "# names gotten from the \"csvdata\" folder, so that each thermal csv file has it's\n",
    "# corresponding GPP value matched to it\n",
    "# NOTE: In addition to matching GPP values, this code also fills in GPP values\n",
    "# for those images without recorded values through linear interpoaltion\n",
    "# NOTE: Currently only works when first CSV is from a 30 min increment\n",
    "dictList = list()\n",
    "\n",
    "counter = 0\n",
    "numLoops = len(csvfiles)\n",
    "oldGPP = -1.1\n",
    "for i in range(0, numLoops, 6):\n",
    "    #GPPDataDict.clear()\n",
    "    currFile = csvfiles[i]\n",
    "    adaptedDate = change_csv_date(currFile)\n",
    "    print(adaptedDate)\n",
    "    currGPP = dateGPPList.at[adaptedDate,\"GPP\"]\n",
    "    if(i == 0):\n",
    "        #GPPDataDict.update({currFile : currGPP})\n",
    "        GPPDataDict = dict()\n",
    "        GPPDataDict.update({\"GPP\" : currGPP})\n",
    "        GPPDataDict.update({\"FILE\" : currFile})\n",
    "        dictList.append(GPPDataDict)\n",
    "        oldGPP = currGPP\n",
    "        continue\n",
    "        \n",
    "    GPPDataDictTemp = dict()\n",
    "    GPPDataDictTemp.update({\"GPP\" : currGPP})\n",
    "    GPPDataDictTemp.update({\"FILE\" : currFile})\n",
    "    \n",
    "    \n",
    "    diffGPP = currGPP - oldGPP\n",
    "    increment = diffGPP / 6.0\n",
    "    for j in range(i-5, i, 1):\n",
    "        oldGPP += increment\n",
    "        currFile = csvfiles[j]\n",
    "        GPPDataDict = dict()\n",
    "        GPPDataDict.update({\"GPP\" : oldGPP})\n",
    "        GPPDataDict.update({\"FILE\" : currFile})\n",
    "        dictList.append(GPPDataDict)\n",
    "    dictList.append(GPPDataDictTemp)\n",
    "    oldGPP = currGPP + increment\n",
    "    oldGPP = currGPP\n",
    "\n",
    "#print(dictList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This writes a NEW master file, with one column containing the\n",
    "# thermal csv file names, and the other column containing their\n",
    "# GPP values as determined from previous code. New file name is \n",
    "# determined by variable csv_file1\n",
    "\n",
    "import csv\n",
    "#saveLocation = \"\"\n",
    "#os.chdir(saveLocation)\n",
    "csv_file1 = \"populatedGPPs.csv\"\n",
    "csv_columns = ['FILE','GPP']\n",
    "try:\n",
    "    with open(csv_file1, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in dictList:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
