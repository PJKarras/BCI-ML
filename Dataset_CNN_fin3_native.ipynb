{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1632,
     "status": "ok",
     "timestamp": 1591470456379,
     "user": {
      "displayName": "Peter Karras",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8cD6ExyaOIfQ0DJPVpcMEP6z-_niPHYwBJiVh2A=s64",
      "userId": "18401168128338827169"
     },
     "user_tz": 240
    },
    "id": "F5mNCDuqMjMW",
    "outputId": "17997de3-3fc5-44d0-fb4c-ad70a394375b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Contains the Custom Dataset creation and the CNN\\n    NOTE: MUST HAVE FILE FROM MAKEMASTER PROGRAM PRIOR TO RUNNING'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peter Karras 2020\n",
    "''' Contains the Custom Dataset creation and the CNN\n",
    "    NOTE: MUST HAVE FILE FROM MAKEMASTER PROGRAM PRIOR TO RUNNING'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time: 401.0922603607178s for 10,000 files\n",
    "#max is: 43.8977567043499\n",
    "#max is: 22.0574247607658\n",
    "# Time: 153.2100191116333 for 4,000 files\n",
    "# max is: 40.046902918943\n",
    "# max is: 22.0574247607658\n",
    "# Time: 98.4042558670044 for 2,500 files\n",
    "# max is: 40.508388402478\n",
    "# min is: 24.8413349715329\n",
    "# Time: 33.11633038520813 for 933 files\n",
    "# max is: 40.3920694022969\n",
    "# min is: 24.8413349715329\n",
    "# Time: for 9000 files\n",
    "# max is: 43.85429664867971\n",
    "# min is: 21.584069668121902\n",
    "\n",
    "# FULL 55000\n",
    "#Time taken (s): 45913.3\n",
    "#Max value is: 43.8977567043499\n",
    "#Min value is: 21.584069668121902\n",
    "\n",
    "# March\n",
    "#Time: 187.95090889930725\n",
    "#max is: 40.342822540551296\n",
    "#min is: 22.0574247607658\n",
    "# April\n",
    "# Time: 286.47614312171936\n",
    "# max is: 43.8977567043499\n",
    "# min is: 23.0867814341884\n",
    "# May\n",
    "# Time: 355.6945369243622\n",
    "# max is: 41.651975331159896\n",
    "# min is: 22.549667363426103\n",
    "# June\n",
    "# Time: 258.5124309062958\n",
    "# max is: 42.1865665374543\n",
    "# min is: 24.2563848704595\n",
    "# July\n",
    "# Time: 117.10082149505615\n",
    "# max is: 40.3920694022969\n",
    "# min is: 23.3752163703192\n",
    "# August\n",
    "# Time: 167.5036985874176\n",
    "# max is: 40.1815051816256\n",
    "# min is: 22.1157735577469\n",
    "# Sep\n",
    "# Time: 252.0023398399353\n",
    "# max is: 43.200494433666\n",
    "# min is: 21.9034323541466\n",
    "\n",
    "\"\"\"\n",
    "epochinfotime\n",
    "\"\"\"\n",
    "# 3batchsize Epochs for 55,000 take 1446 s per epoch\n",
    "# Epochs for 10,000 files take 280 s per epoch\n",
    "# Epochs for 4,000 files take 101 s per epoch\n",
    "# Epochs for 2,500 files take 65 s per epoch\n",
    "# Epochs for 933 files take 24 s per epoch\n",
    "\n",
    "\"\"\" \n",
    "EPOCH TIME CALC\n",
    "\"\"\"\n",
    "# fileSize = 5000.0\n",
    "# minutesToTrain = 60 * 3\n",
    "\n",
    "# secondsPerEpoch = (0.0287*(fileSize) - 6.4268)\n",
    "# secondsToTrain = minutesToTrain * 60.0\n",
    "# epochsToUse = secondsToTrain/secondsPerEpoch\n",
    "# print(\"To train for\", minutesToTrain, \"minutes use\", epochsToUse, \"epochs\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjKURHC6MjMc"
   },
   "outputs": [],
   "source": [
    "\"\"\" IMPORT NEEDED MODULES \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset  # For custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1042,
     "status": "ok",
     "timestamp": 1591470467686,
     "user": {
      "displayName": "Peter Karras",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8cD6ExyaOIfQ0DJPVpcMEP6z-_niPHYwBJiVh2A=s64",
      "userId": "18401168128338827169"
     },
     "user_tz": 240
    },
    "id": "lBadNzhPvsZl",
    "outputId": "844e9a72-6b82-4750-d049-717cd53e8613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/\n"
     ]
    }
   ],
   "source": [
    "# Issues with directories, use this to reset cwd and then move into desired directory \n",
    "#os.chdir(\"/content\")\n",
    "startingDir = os.getcwd()\n",
    "if startingDir != r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/\":\n",
    "    startingDir = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/\"\n",
    "print(startingDir)\n",
    "csvfilesMLLocation = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/csvdataFULL/BCIML_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcFs2C-GMjMf"
   },
   "outputs": [],
   "source": [
    "\"\"\" CREATE CUSTOM DATASET \"\"\"\n",
    "# Pulls from pool of 900 thermal images\n",
    "class BCIDataset2(Dataset):\n",
    "    def __init__(self, csv_master_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_master_path (string): path to csv file with thermal image (csv's) file paths\n",
    "            as first column and GPP values as the second column, rows are one set of\n",
    "            correlating data points\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        # Transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        # Read the csv file \n",
    "        #self.data_info = pd.read_csv(csv_master_path, header=None)\n",
    "        self.data_info = pd.read_csv(csv_master_path)\n",
    "        # First column contains thermal image (csv's) file paths\n",
    "        self.thermal_path_arr = np.asarray(self.data_info.iloc[:,0])\n",
    "        # Second column is the GPP values for the images from first column\n",
    "        self.GPP_arr = np.asarray(self.data_info.iloc[:,1])        \n",
    "        self.transform = transforms.ToTensor()\n",
    "        max_list = np.full(1,-10)\n",
    "        min_list = np.full(1, 99999)\n",
    "        os.chdir(csvfilesMLLocation)\n",
    "        start = time.time()\n",
    "#         for filename in self.thermal_path_arr:\n",
    "#             file_temps = pd.read_csv(filename)\n",
    "#             file_temps_vals = file_temps.values\n",
    "#             torch_temps = torch.from_numpy(file_temps_vals)\n",
    "#             max_list = np.append(max_list, [torch.max(torch_temps)])\n",
    "#             min_list = np.append(min_list, [torch.min(torch_temps)])\n",
    "#         self.ABS_MAX = (torch.max(torch.from_numpy(max_list))).item()\n",
    "#         self.ABS_MIN = (torch.min(torch.from_numpy(min_list))).item()\n",
    "        self.ABS_MAX = 40.3920694022969\n",
    "        self.ABS_MIN = 23.3752163703192\n",
    "        print(f'Time: {time.time()-start}')\n",
    "        print(\"max is:\", self.ABS_MAX)\n",
    "        print(\"min is:\", self.ABS_MIN)\n",
    "            \n",
    "        \n",
    "    #NOTE: might need to flip image\n",
    "    def __getitem__(self, index):\n",
    "        # Get thermal image (csv) path\n",
    "        single_thermal_path = self.thermal_path_arr[index]\n",
    "        # Convert csv to pandas dataframe\n",
    "        pd_thermal_img = pd.read_csv(single_thermal_path)\n",
    "        # Convert pandas dataframe to numpy array\n",
    "        ###np_thermal_img = np.asarray(pd_thermal_img.iloc[:,1:])\n",
    "        np_thermal_img = np.asarray(pd_thermal_img)\n",
    "        # Normalization of values from orignal csv file, translates thermal values to 0-1 range\n",
    "        # https://stats.stackexchange.com/questions/70801/how-to-normalize-data-to-0-1-range\n",
    "        np_normalized_temp_no_channel = ((np_thermal_img-self.ABS_MIN)/(self.ABS_MAX - self.ABS_MIN))\n",
    "        # Flip image by 90 degrees, is commented out currently as might mess with network architecture\n",
    "        #np_thermal_img = np.rot90(np_thermal_img)\n",
    "        # Add num channels dimension and format correctly\n",
    "        np_normalized_temp = np.expand_dims(np_normalized_temp_no_channel, axis=0)\n",
    "        # Transform numpy array to tensor\n",
    "        tensor_normal_thermal_vals = torch.from_numpy(np_normalized_temp)\n",
    "        # Get GPP value for image\n",
    "        single_image_GPP = self.GPP_arr[index]\n",
    "        return(tensor_normal_thermal_vals, single_image_GPP)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Working network\"\"\"\n",
    "class BCIModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCIModel, self).__init__()\n",
    "        # Convulutional Layer 1 (sees 320 x 240 x 1 image tensor)\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding = 1)\n",
    "        # Convulutional Layer 2 (sees 160 x 120 x 16 image tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
    "        # Convulutional Layer 3 (sees 80 x 60 x 32 tensor, reduced height and width from max pooling layer and stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        # Convulutional Layer 4 (sees 40 x 30 x 64 tensor, reduced height and width from max pooling layer and stride=2)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3, padding = 1)\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        # Linear and Batchnorm Layers\n",
    "        self.fc1 = nn.Linear(128 * 20 * 15, 100)\n",
    "        self.BatchN = nn.BatchNorm1d(100)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "        \n",
    "        # Dropout Layer\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Add sequence of convulutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 128 * 20 * 15)\n",
    "        # Add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # Add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # Add last layer\n",
    "        x = (self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mIX8CIzRMjMi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.0\n",
      "max is: 40.3920694022969\n",
      "min is: 23.3752163703192\n",
      "BCIModel(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=38400, out_features=100, bias=True)\n",
      "  (BatchN): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n",
      "CUDA is available!  Training on GPU ...\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "GeForce RTX 2070 SUPER\n",
      "Memory Usage:\n",
      "Allocated: 0.1 GB\n",
      "Cached:    0.1 GB\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "\n",
    "    LOAD IN DATA \n",
    "\n",
    "\"\"\"\n",
    "os.chdir(startingDir)\n",
    "# Number of subprocesses to use for data loading\n",
    "# Using advice of 4 workers per GPU\n",
    "# Getting errors with any # of workers > 0\n",
    "num_workers = 0\n",
    "\n",
    "# Proportion of training set to use for validation and testing\n",
    "# Note: this will be split in equal halves, one for validation, one for testing\n",
    "valid_and_test_proportion = 0.3\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "# Define custom datasets, for training and for testing\n",
    "# Note: Will be using 10,000 data for testing, 50,000 data for training in future\n",
    "month = \"JUL\"\n",
    "masterfileMLLocation = csvfilesMLLocation + r\"/populatedGPPs\" + month + \".csv\"\n",
    "BCIDataset = BCIDataset2(masterfileMLLocation)\n",
    "\n",
    "# Obtain indices for training, validation and testing datasets\n",
    "num_train = len(BCIDataset)         # Number of data points (csv files to be used)\n",
    "indices1 = list(range(num_train))   # indices of [0,num_train) to represent data\n",
    "np.random.shuffle(indices1)         # Shuffled indices\n",
    "# Splitting training from validation/testing\n",
    "split1 = int(np.floor(valid_and_test_proportion * num_train))\n",
    "\n",
    "train_indices, valid_and_test_indices = indices1[split1:], indices1[:split1]\n",
    "# Splitting validation/testing up into their individual groups\n",
    "num_valid_test = len(valid_and_test_indices)\n",
    "\n",
    "split2 = int(np.floor(0.5 * num_valid_test))\n",
    "valid_indices, test_indices = valid_and_test_indices[split2:], valid_and_test_indices[:split2]\n",
    "\n",
    "# SAVE Indices in case further training is needed, dont want to overfit the data\n",
    "os.chdir(startingDir)\n",
    "titlesIndicesData = [\"train_indices\",\"valid_indices\",\"test_indices\"]\n",
    "indicesFile = \"indices_data_\" + month +\".csv\"\n",
    "with open(indicesFile,'w',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(titlesIndicesData)\n",
    "    counter = 0\n",
    "    for train in train_indices:\n",
    "        if counter >= len(test_indices): \n",
    "            test = -1\n",
    "        else:\n",
    "            test = test_indices[counter]\n",
    "        if counter >= len(valid_indices): \n",
    "            valid = -1\n",
    "        else:\n",
    "            valid = valid_indices[counter]\n",
    "        counter = counter + 1\n",
    "        writer.writerow([train,valid,test])\n",
    "\n",
    "# Define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Batch Making\n",
    "\n",
    "\"\"\"\n",
    "# How many samples per batch to load\n",
    "batch_size = 6\n",
    "# Prepare data loaders \n",
    "train_loader = torch.utils.data.DataLoader(BCIDataset, batch_size=batch_size,\n",
    "                                           sampler=train_sampler, num_workers=num_workers, pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(BCIDataset, batch_size=batch_size,\n",
    "                                           sampler=valid_sampler, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(BCIDataset, batch_size=batch_size,\n",
    "                                           sampler=test_sampler, num_workers=num_workers, pin_memory=True)\n",
    "\"\"\"\n",
    "\n",
    "    Initialize model, optimizer, LR schedueler\n",
    "\n",
    "\"\"\"\n",
    "# Initialize model\n",
    "model = BCIModel()\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr =0.0001)\n",
    "# defining the scheduler, to handle learning rate changes\n",
    "#scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.97)\n",
    "#scheduler = optim.lr_scheduler.CyclicLR(optimizer, gamma = 0.97)\n",
    "    \n",
    "# defining loss function\n",
    "criterion = nn.MSELoss()\n",
    "print(model)\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    model.cuda()\n",
    "    \n",
    "    \n",
    "torch.cuda.empty_cache()\n",
    "# Optimization? Best for inputs that do not change in size (this network)\n",
    "# \"This flag allows you to enable the inbuilt cudnn auto-tuner to find the best algorithm to use for your hardware\"\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Check that we are on GPU\n",
    "for p in model.parameters():\n",
    "    print(p.device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471\n",
      "470\n",
      "2198\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_indices))\n",
    "print(len(test_indices))\n",
    "print(len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 131232,
     "status": "ok",
     "timestamp": 1591473306765,
     "user": {
      "displayName": "Peter Karras",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8cD6ExyaOIfQ0DJPVpcMEP6z-_niPHYwBJiVh2A=s64",
      "userId": "18401168128338827169"
     },
     "user_tz": 240
    },
    "id": "cOi9LHgQMjMt",
    "outputId": "2a6e86ea-855b-4d6e-fb81-c9ca913f9ae2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #: 1\n",
      "Epoch: 1 \tTraining Loss: 110.675204 \tValidation Loss: 79.629101\n",
      "Validation loss decreased (inf --> 79.629101).  Saving model ...\n",
      "Time: 106.28587293624878\n",
      "Current Time = 22:44:25\n",
      "LR: 0.0001\n",
      "Epoch #: 2\n",
      "Epoch: 2 \tTraining Loss: 118.729586 \tValidation Loss: 91.460030\n",
      "Time: 79.03555417060852\n",
      "Current Time = 22:45:44\n",
      "LR: 0.0035\n",
      "Epoch #: 3\n",
      "Epoch: 3 \tTraining Loss: 125.524034 \tValidation Loss: 91.255702\n",
      "Time: 79.71174621582031\n",
      "Current Time = 22:47:04\n",
      "LR: 0.007\n",
      "Epoch #: 4\n",
      "Epoch: 4 \tTraining Loss: 121.342565 \tValidation Loss: 211.178201\n",
      "Time: 86.85773539543152\n",
      "Current Time = 22:48:31\n",
      "LR: 0.0105\n",
      "Epoch #: 5\n",
      "Epoch: 5 \tTraining Loss: 206.517781 \tValidation Loss: 197.170896\n",
      "Time: 83.56266593933105\n",
      "Current Time = 22:49:55\n",
      "LR: 0.014\n",
      "Epoch #: 6\n",
      "Epoch: 6 \tTraining Loss: 201.145002 \tValidation Loss: 201.612816\n",
      "Time: 88.13259434700012\n",
      "Current Time = 22:51:23\n",
      "LR: 0.0175\n",
      "Epoch #: 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-63999199a435>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# Backward pass: compute gradient of the loss with respect to model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;31m#torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# Perform a single optimization step (parameter update)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" TRAINING OF MODEL \"\"\"\n",
    "\n",
    "os.chdir(startingDir)\n",
    "#csvfilesMLLocation = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/csvdata10000\"\n",
    "os.chdir(csvfilesMLLocation)\n",
    "# Number of epochs to train the model\n",
    "# try 10, 100, 500, 1000\n",
    "n_epochs = 55\n",
    "test_loss = 0.0\n",
    "valid_loss_min = np.Inf    # Track change in validation loss, set\n",
    "\n",
    "\n",
    "train_loss_vals = []\n",
    "valid_loss_vals = []\n",
    "epochCounter = []\n",
    "lr_vals = []\n",
    "time_taken_vals = []\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    epochCounter.append(epoch)\n",
    "    lr_vals.append(optimizer.param_groups[0]['lr'])    \n",
    "    # Measurement of epoch times\n",
    "    start = time.time()\n",
    "    print(\"Epoch #:\", epoch)\n",
    "    # Keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.float(), target.float()\n",
    "        # Move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # Clear the gradients fo all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # Fixes shape\n",
    "        output = torch.flatten(output)\n",
    "        # Calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # Update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "         \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        data, target = data.float(), target.float()\n",
    "        # Move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # Fixes shape\n",
    "        output = torch.flatten(output)\n",
    "        # Calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # Update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # Calculate avearage losses\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "    # Update validation loss list\n",
    "    valid_loss_vals.append(valid_loss)\n",
    "    # Update training loss list\n",
    "    train_loss_vals.append(train_loss)\n",
    "    \n",
    "    # Print training/validation stats\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_BCI_' + month + '.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "        \n",
    "    # save model no matter performance\n",
    "    torch.save(model.state_dict(), 'model_BCI_unoptim_' + month + '.pt')\n",
    "    \n",
    "    # End of time check\n",
    "    print(f'Time: {time.time()-start}')\n",
    "    time_taken_vals.append(time.time()-start)\n",
    "    # Time of completion\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    print(\"LR:\",optimizer.param_groups[0]['lr'])        \n",
    "\n",
    "    #     if epoch >= 40:\n",
    "#         scheduler.step()\n",
    "    \n",
    "    optimizer.param_groups[0]['lr'] = epoch * 0.0035\n",
    "\n",
    "print(\"Operation Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss_vals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-163ace7287a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtemp_train_loss_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loss_vals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtemp_valid_loss_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_loss_vals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtemp_epochCounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtemp_lr_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_vals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loss_vals' is not defined"
     ]
    }
   ],
   "source": [
    "temp_train_loss_vals = train_loss_vals\n",
    "temp_valid_loss_vals = valid_loss_vals\n",
    "temp_epochCounter = epochCounter\n",
    "temp_lr_vals = lr_vals\n",
    "print(train_loss_vals)\n",
    "print(valid_loss_vals)\n",
    "print(epochCounter)\n",
    "print(lr_vals)\n",
    "os.chdir(startingDir)\n",
    "titlesTrainingData = [\"epoch\",\"train_loss\",\"valid_loss\",\"learning_rate\",\"time_taken\"]\n",
    "trainFileStats = \"training_data_\" + month +\".csv\"\n",
    "print(trainFileStats)\n",
    "with open(trainFileStats,'w',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(titlesTrainingData)\n",
    "    for epoch, train, valid, lr, time in zip(epochCounter, train_loss_vals, valid_loss_vals, lr_vals, time_taken_vals):\n",
    "        writer.writerow([epoch,train,valid,lr,time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\Desktop\\Thermo_R_Code\\FinalThermo\\new2\\csvdataFULL\\BCIML_Dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x72 with 0 Axes>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x72 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" CREATION OF TEST RANGE LR PLOT \"\"\"\n",
    "print(os.getcwd())\n",
    "plt.scatter(epochCounter, valid_loss_vals, c=\"red\")\n",
    "#plt.xlim(0,0.05)\n",
    "# plt.ylim(0,100)\n",
    "plt.figure(figsize=(15,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" CREATION OF GENERALIZATION PLOT \"\"\"\n",
    "# genPlotFig =plt.figure()\n",
    "# genPlotFig.add_axes([0,0,1,1])\n",
    "# ax.scatter(epochCounter, train_loss_vals, color='r')\n",
    "# ax.scatter(epochCounter, valid_loss_vals, color='b')\n",
    "\n",
    "# ax.set_title('Genralization Plot')\n",
    "fig=plt.figure(figsize=(10.0, 5.0))\n",
    "colors = (\"red\", \"green\")\n",
    "groups = (\"training\", \"validation\")\n",
    "data = ((epochCounter, train_loss_vals), (epochCounter, valid_loss_vals))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "for data, color, group in zip(data, colors, groups):\n",
    "    x, y = data\n",
    "    ax.scatter(x, y, alpha=0.8, c=color, edgecolors='none', s=30, label=group)\n",
    "    plt.plot(x,y,'-o',c=color)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MSE')\n",
    "y = np.array([2,4,6,8,10,12,14,16,18])\n",
    "plt.xticks(np.arange(0, n_epochs+2, step=2))\n",
    "\n",
    "plt.title(\"Generalization Plot for \" + month)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "os.chdir(startingDir)\n",
    "my_dpi=96\n",
    "fig.savefig(\"generalizationPlot\"+month,dpi=my_dpi*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5441,
     "status": "ok",
     "timestamp": 1591473317804,
     "user": {
      "displayName": "Peter Karras",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8cD6ExyaOIfQ0DJPVpcMEP6z-_niPHYwBJiVh2A=s64",
      "userId": "18401168128338827169"
     },
     "user_tz": 240
    },
    "id": "smfzuBVjMjMw",
    "outputId": "decad9c1-c468-49f5-b190-7d5f9c4861ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from 0 : 1.6003055572509766\n",
      "Output of network:\t tensor([16.9033, 26.7295,  0.5900,  0.5900,  0.5900,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([15.4137, 24.2820,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "loss from this run: 1.6003055572509766\n",
      "Output 1 : 16.903270721435547\n",
      "Output 2 : 26.72953224182129\n",
      "Target 1 : 15.413675308227539\n",
      "Target 2 : 24.281963348388672\n",
      "test loss from 1 : 13.916994094848633\n",
      "Output of network:\t tensor([ 6.6100, 33.1317,  0.5900,  0.9931, 28.5318,  1.2045], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 8.6672, 34.5709,  0.0000,  0.0000, 19.8696,  0.2936], device='cuda:0') \n",
      "\n",
      "loss from this run: 13.916994094848633\n",
      "Output 1 : 6.610044479370117\n",
      "Output 2 : 33.1317138671875\n",
      "Output 5 : 28.531841278076172\n",
      "Target 1 : 8.667219161987305\n",
      "Target 2 : 34.57094192504883\n",
      "Target 5 : 19.86959457397461\n",
      "test loss from 2 : 31.344465255737305\n",
      "Output of network:\t tensor([24.0896, 32.1312,  3.0652, 16.3050,  0.5900,  1.8234], device='cuda:0')\n",
      "Target Values:\t\t tensor([27.7662, 42.4862,  2.0098, 21.3781,  0.0000,  8.1580], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 0.9686456918716431\n",
      "Output of network:\t tensor([1.6444, 1.1262, 0.5900, 0.5900, 1.0088, 1.6444], device='cuda:0')\n",
      "Target Values:\t\t tensor([1.9989, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 22.204275131225586\n",
      "Output of network:\t tensor([23.7913,  0.5900, 24.3460,  0.5900,  6.5768,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([34.5306,  0.0000, 20.8189,  0.0000,  8.6766,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 14.041144371032715\n",
      "Output of network:\t tensor([26.6874, 25.3769,  0.5900,  0.7208,  1.3175,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([32.8366, 31.9710,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 42.31398010253906\n",
      "Output of network:\t tensor([ 2.1650, 25.3232,  3.4381,  0.8799, 16.4558, 25.3211], device='cuda:0')\n",
      "Target Values:\t\t tensor([13.3807, 23.0908,  0.0000,  0.0000,  7.3369, 30.5517], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 28.287389755249023\n",
      "Output of network:\t tensor([ 0.5900,  0.5900,  0.5900, 19.5049,  0.6484, 22.4260], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  0.0000, 23.8241,  0.0000, 34.6572], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 13.296140670776367\n",
      "Output of network:\t tensor([22.0620,  0.8025,  1.7871,  1.8815, 25.9225,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([24.6775,  0.0000,  2.4526,  5.6245, 33.5047,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 32.70201873779297\n",
      "Output of network:\t tensor([ 2.4228,  0.7201,  0.8062,  2.9208, 20.2976,  0.6685], device='cuda:0')\n",
      "Target Values:\t\t tensor([0.0000, 0.0000, 0.0000, 8.7650, 7.8649, 0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 15.311651229858398\n",
      "Output of network:\t tensor([ 1.5489, 19.8466,  3.7166,  0.5900, 16.4558,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 27.3993,  0.0000,  0.0000, 12.2228,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 1.719813346862793\n",
      "Output of network:\t tensor([ 7.5005,  1.1914,  0.5900, 21.1651,  0.6723,  4.0637], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 6.7665,  0.0000,  0.0000, 22.2650,  0.0000,  6.5838], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 17.9046630859375\n",
      "Output of network:\t tensor([ 2.3080,  0.5900, 13.4914, 20.1652, 24.0306, 26.3948], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 6.7758,  0.0000,  9.7978, 28.5315, 25.1301, 27.9022], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 15.68222713470459\n",
      "Output of network:\t tensor([30.7550,  3.6350,  6.6100,  1.9421,  5.3180, 21.2364], device='cuda:0')\n",
      "Target Values:\t\t tensor([28.6300, 11.9951,  8.4719,  0.0000,  8.3441, 23.0504], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 30.694076538085938\n",
      "Output of network:\t tensor([ 0.5900, 18.5265,  3.0164,  2.5499, 20.6875, 24.6940], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 28.9685,  0.0000,  0.8175, 28.5238, 23.5645], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 19.364601135253906\n",
      "Output of network:\t tensor([ 6.8182,  0.5900, 23.2619, 14.7179,  2.3584,  2.8418], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 6.8685,  0.0000, 33.3318, 16.2146,  0.3291,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 28.957645416259766\n",
      "Output of network:\t tensor([ 9.3930,  0.5900,  0.8354,  0.5900, 25.4128,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([22.1730,  0.0000,  0.0000,  0.0000, 28.3580,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 1.002243995666504\n",
      "Output of network:\t tensor([0.6344, 0.5900, 0.6606, 4.1856, 1.8637, 0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([0.0000, 0.0000, 0.0000, 5.1881, 0.0000, 0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 4.188357353210449\n",
      "Output of network:\t tensor([26.8906,  0.7336,  1.2943, 18.1235, 25.0381,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([28.5737,  0.0000,  0.0000, 22.5636, 24.8916,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 28.5965633392334\n",
      "Output of network:\t tensor([ 1.9698, 26.9282, 19.9248,  0.6160,  1.6011,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 28.9844, 32.6675,  0.0000,  2.2073,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 9.063949584960938\n",
      "Output of network:\t tensor([ 0.5900,  3.7166, 15.3837,  1.6562,  1.1170,  0.6022], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000, 21.4507,  0.0000,  1.6723,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 9.607786178588867\n",
      "Output of network:\t tensor([24.1971,  0.5900, 24.0172,  0.5900,  0.5900,  1.5669], device='cuda:0')\n",
      "Target Values:\t\t tensor([18.1578,  0.0000, 28.2214,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 3.183063268661499\n",
      "Output of network:\t tensor([ 0.6954, 26.8979,  1.2128,  0.5900,  3.4432, 27.3392], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 27.0687,  0.0000,  0.0000,  6.5042, 30.0590], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 20.76388931274414\n",
      "Output of network:\t tensor([15.4834,  7.3202,  1.8480,  0.5900,  0.5900,  2.0178], device='cuda:0')\n",
      "Target Values:\t\t tensor([13.0355, 17.9708,  0.0000,  0.0000,  0.0000,  3.0394], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 16.69779396057129\n",
      "Output of network:\t tensor([ 0.5900,  0.5900,  0.6233, 22.0102, 11.6669, 35.1984], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  0.0000, 25.2335, 13.9381, 44.3392], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 34.830745697021484\n",
      "Output of network:\t tensor([13.8360,  0.5900, 17.0922,  1.0517,  0.9000,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([13.5768,  0.0000, 31.4555,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 49.41929244995117\n",
      "Output of network:\t tensor([2.2581, 2.2805, 4.5277, 0.5900, 4.3012, 2.3990], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  1.9802,  0.0000,  0.0000, 18.5507], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 24.12778091430664\n",
      "Output of network:\t tensor([ 8.4485,  0.5900, 12.6506,  2.1845,  1.2616,  1.8279], device='cuda:0')\n",
      "Target Values:\t\t tensor([18.5736,  0.0000, 18.5725,  0.0000,  0.0000,  2.5124], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 61.98606872558594\n",
      "Output of network:\t tensor([ 0.5900,  0.8054, 24.6192,  3.3787,  1.6755, 27.3006], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  6.6857,  2.6874,  0.0000, 34.0847], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 49.111045837402344\n",
      "Output of network:\t tensor([ 2.5045, 18.2608,  0.5900, 26.8445,  0.5900,  9.8789], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 28.9120,  0.0000, 39.9274,  0.0000,  8.1220], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 2.174133062362671\n",
      "Output of network:\t tensor([17.1349,  0.6418,  2.4911,  2.4552,  0.5900,  1.0999], device='cuda:0')\n",
      "Target Values:\t\t tensor([15.2782,  0.0000,  1.2263,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 6.43475341796875\n",
      "Output of network:\t tensor([ 0.5900,  0.5900, 22.9326, 34.6923,  0.5900,  1.2483], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000, 23.6060, 39.8275,  0.0000,  4.5256], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 28.415023803710938\n",
      "Output of network:\t tensor([ 8.4485,  0.5900,  0.6007,  9.8789,  2.3790, 16.8470], device='cuda:0')\n",
      "Target Values:\t\t tensor([19.7037,  0.0000,  0.0000, 10.0579,  0.0000, 10.7307], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 9.33212661743164\n",
      "Output of network:\t tensor([ 2.6466,  0.5900,  1.4038,  0.5900, 10.4909,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 1.3164,  0.0000,  0.0000,  0.0000, 17.6469,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 70.15154266357422\n",
      "Output of network:\t tensor([0.5900, 0.5900, 1.5150, 1.3426, 8.7365, 4.5399], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  5.9731,  0.0000, 12.7997, 24.0854], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 29.931119918823242\n",
      "Output of network:\t tensor([23.8303,  1.6216, 14.5348,  7.1816,  0.7356,  3.0593], device='cuda:0')\n",
      "Target Values:\t\t tensor([24.1304,  0.0000, 12.1066, 19.8729,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 0.4282848834991455\n",
      "Output of network:\t tensor([0.5900, 0.5900, 0.8456, 0.7858, 2.0025, 0.8262], device='cuda:0')\n",
      "Target Values:\t\t tensor([0.0000, 0.0000, 0.0000, 1.7723, 2.3618, 1.0634], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 0.8460904955863953\n",
      "Output of network:\t tensor([0.5902, 6.4668, 0.8625, 0.5900, 1.5037, 0.9501], device='cuda:0')\n",
      "Target Values:\t\t tensor([0.0000, 5.7795, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 4.716548919677734\n",
      "Output of network:\t tensor([ 3.5619, 31.8925,  0.5900,  0.6831, 19.5928, 20.4336], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 5.9787, 34.6638,  0.0000,  0.0000, 18.9093, 16.7599], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 4.42387580871582\n",
      "Output of network:\t tensor([6.1544, 2.7448, 1.9412, 8.4528, 3.4825, 4.3742], device='cuda:0')\n",
      "Target Values:\t\t tensor([5.7033, 0.0000, 2.0439, 6.9162, 6.7220, 1.9371], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 41.17713928222656\n",
      "Output of network:\t tensor([30.0455,  0.5900, 14.5101,  5.4516,  9.0349,  3.2011], device='cuda:0')\n",
      "Target Values:\t\t tensor([22.2220,  0.0000, 24.8918, 12.0863, 13.8786,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 5.505487442016602\n",
      "Output of network:\t tensor([13.8360,  4.8181, 31.8925,  0.5900,  1.1262,  1.4597], device='cuda:0')\n",
      "Target Values:\t\t tensor([15.9854,  0.0000, 33.0974,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 20.00665855407715\n",
      "Output of network:\t tensor([ 5.4516, 35.6918, 25.2506,  1.2865, 12.2942, 15.3226], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 8.8529, 29.6271, 26.1702,  0.0000, 11.7335, 23.6217], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 9.500044822692871\n",
      "Output of network:\t tensor([ 1.8981,  0.8515,  0.9000, 28.0745, 21.6863,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  0.4997, 35.2914, 21.9687,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 27.133419036865234\n",
      "Output of network:\t tensor([26.6295, 31.1155, 19.5726,  0.5900, 16.6604,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([30.0719, 33.9659, 28.3604,  0.0000,  8.6041,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 32.51656723022461\n",
      "Output of network:\t tensor([ 8.1095,  1.0999,  0.5900, 24.8742, 24.2377,  9.2343], device='cuda:0')\n",
      "Target Values:\t\t tensor([20.8607,  0.0000,  0.0000, 30.3881, 24.7092,  9.8042], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 5.1138014793396\n",
      "Output of network:\t tensor([ 0.5900, 16.1827,  0.9904, 12.8921, 19.3518,  5.1903], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 18.5095,  0.0000,  9.3865, 21.5414,  7.8089], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 8.529431343078613\n",
      "Output of network:\t tensor([28.1092, 22.2306, 27.2728,  0.5900, 17.1443,  8.5862], device='cuda:0')\n",
      "Target Values:\t\t tensor([28.0761, 21.5712, 29.4392,  0.0000, 10.4149,  7.9421], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 8.941736221313477\n",
      "Output of network:\t tensor([ 0.5900,  0.6993,  3.7159,  0.5900, 25.8895, 15.8714], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000, 10.7811,  0.0000, 26.1558, 17.4454], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 13.070625305175781\n",
      "Output of network:\t tensor([ 1.8273, 15.5678,  4.2489,  0.5900,  0.5900,  6.4202], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 21.9527,  6.9615,  0.0000,  0.0000,  1.2953], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 13.14150619506836\n",
      "Output of network:\t tensor([ 4.8004,  2.1650,  0.5900, 19.6765,  0.5900,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 2.0250, 10.4544,  0.0000, 20.8548,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 53.521846771240234\n",
      "Output of network:\t tensor([14.2531,  6.4668,  0.5900,  5.6877, 24.3503,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([24.6836,  5.5865,  0.0000, 20.0709, 26.3475,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 18.41504669189453\n",
      "Output of network:\t tensor([ 5.0583,  3.0987, 26.2106,  6.4146,  1.4038,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  2.7716, 33.0660,  0.4581,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 4.876967906951904\n",
      "Output of network:\t tensor([0.5900, 6.7859, 0.5900, 0.8068, 8.6338, 7.4827], device='cuda:0')\n",
      "Target Values:\t\t tensor([0.0000, 1.6685, 0.0000, 0.0000, 9.9329, 7.2831], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 1.4632089138031006\n",
      "Output of network:\t tensor([1.4038, 6.4688, 1.2385, 0.9606, 0.5900, 1.8914], device='cuda:0')\n",
      "Target Values:\t\t tensor([0.2329, 7.4817, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 13.599180221557617\n",
      "Output of network:\t tensor([ 0.5900,  0.5900,  0.5900, 17.6796, 12.2494,  0.6982], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  0.0000, 26.5547, 13.3871,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 13.833261489868164\n",
      "Output of network:\t tensor([28.1978,  9.4908,  0.5900,  2.0144, 19.4380, 19.5928], device='cuda:0')\n",
      "Target Values:\t\t tensor([29.8833,  8.7249,  0.0000,  0.0000, 28.0500, 20.5925], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 2.7682113647460938\n",
      "Output of network:\t tensor([ 0.5999, 10.2634,  0.5900, 11.6669,  7.9085,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  9.1600,  0.0000, 15.4370,  8.2580,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 6.821723461151123\n",
      "Output of network:\t tensor([0.5900, 9.2284, 9.7492, 2.8418, 2.9765, 0.6057], device='cuda:0')\n",
      "Target Values:\t\t tensor([0.0000, 7.4638, 9.5165, 0.0000, 8.3591, 0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 50.446502685546875\n",
      "Output of network:\t tensor([ 0.5900, 10.4177,  4.7503,  0.5900,  5.7783, 12.1010], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 14.1892,  0.0000,  0.0000,  2.2008, 27.9879], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 8.274691581726074\n",
      "Output of network:\t tensor([17.2417,  0.5900,  2.2547, 21.9174, 21.7222,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([18.1030,  0.0000,  0.0000, 16.9024, 25.9621,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 7.583972930908203\n",
      "Output of network:\t tensor([ 2.0144,  1.8804, 35.5109,  0.5900,  2.0478,  7.5276], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.3381,  0.0000, 40.8230,  0.0000,  0.0000,  4.9982], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 9.502470016479492\n",
      "Output of network:\t tensor([ 0.5900,  3.9296,  8.3002,  1.9850, 19.0816, 14.6483], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  4.0059,  2.2610, 22.9622, 17.4138], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 28.49281120300293\n",
      "Output of network:\t tensor([31.0292,  1.1623, 12.6909,  0.5900, 19.9580, 24.6484], device='cuda:0')\n",
      "Target Values:\t\t tensor([27.3859,  0.0000,  7.5487,  0.0000,  8.5997, 23.9198], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 3.0127782821655273\n",
      "Output of network:\t tensor([ 0.5900,  0.5900,  1.9698, 33.1670,  0.5900,  0.6190], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  0.0000, 36.7404,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 2.884394407272339\n",
      "Output of network:\t tensor([28.3601,  0.5900,  5.8267,  1.1192, 17.5649,  9.5979], device='cuda:0')\n",
      "Target Values:\t\t tensor([26.3561,  0.0000,  3.3975,  0.0000, 17.5485, 12.0039], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 4.510268688201904\n",
      "Output of network:\t tensor([ 1.5683,  8.2909, 14.6384,  1.0696,  3.5808,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 10.2203, 17.2007,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 12.082664489746094\n",
      "Output of network:\t tensor([ 1.1615,  0.7431,  0.6078,  0.6453,  0.5900, 25.9830], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 1.9751,  0.0000,  0.7020,  0.0000,  0.0000, 17.5861], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 13.371231079101562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of network:\t tensor([ 0.5900,  1.7358, 20.1161,  0.5900, 36.4821, 11.8337], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  7.2560, 23.2214,  0.0000, 35.4535, 18.0271], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 4.278385639190674\n",
      "Output of network:\t tensor([ 1.0966,  3.1957, 17.8611,  0.5900, 10.2861,  2.3383], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000, 15.3368,  0.0000,  8.8482,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 11.08878231048584\n",
      "Output of network:\t tensor([ 0.7531,  0.7239, 20.2976,  1.1615,  0.5900, 26.3015], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000, 13.0072,  0.0000,  0.0000, 23.0467], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 1.032107949256897\n",
      "Output of network:\t tensor([ 0.5900,  1.7833, 21.7802,  0.5900,  2.1651,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  2.2904, 22.2313,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 1.0260910987854004\n",
      "Output of network:\t tensor([1.2407, 1.1311, 5.3330, 0.5900, 0.5999, 0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([0.0000, 0.0000, 6.8437, 0.0000, 0.0000, 0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 20.07705307006836\n",
      "Output of network:\t tensor([ 0.5900, 23.3364, 16.9577,  0.5900,  3.4825, 25.8065], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 29.1857, 20.1151,  0.0000,  6.7653, 17.7563], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 6.32321310043335\n",
      "Output of network:\t tensor([0.5900, 4.8149, 0.6379, 0.6284, 1.1927, 4.3047], device='cuda:0')\n",
      "Target Values:\t\t tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 7.7953], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 35.443546295166016\n",
      "Output of network:\t tensor([ 0.6799,  1.4662, 21.2364, 21.3998, 21.8256,  2.7185], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  1.9661, 20.8494, 26.9276, 32.9475, 10.3045], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 0.6768553256988525\n",
      "Output of network:\t tensor([ 0.5900,  6.8006,  0.9193,  0.5900, 12.8921,  0.6606], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  8.1124,  0.0000,  0.0000, 12.2899,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 2.6592791080474854\n",
      "Output of network:\t tensor([ 0.8726,  0.5922, 19.0117,  4.2310, 28.9251,  5.2803], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000, 22.2677,  6.0657, 28.8683,  4.3463], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 6.007564544677734\n",
      "Output of network:\t tensor([ 3.8002, 24.4485,  0.8508,  0.5937,  0.8547,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 28.9261,  1.2016,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 34.661964416503906\n",
      "Output of network:\t tensor([25.4759,  2.3457,  2.5826,  0.5900,  1.6295,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([32.5229, 14.5232,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 6.622223854064941\n",
      "Output of network:\t tensor([ 0.6381, 10.1773,  0.5900, 15.3178,  0.6187, 33.1317], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 13.4630,  0.0000, 10.2905,  0.0000, 31.5423], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 9.634363174438477\n",
      "Output of network:\t tensor([ 0.5900, 29.1679,  4.4210,  0.5900,  2.2231,  1.4484], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 36.2328,  4.0235,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 10.56450080871582\n",
      "Output of network:\t tensor([ 1.5716,  0.5900,  0.5900, 35.5478, 27.4076,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  0.0000, 35.1605, 35.1356,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 17.63636589050293\n",
      "Output of network:\t tensor([ 2.1616, 16.5296, 18.3018,  0.5900,  5.9219,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 1.3977, 22.8743, 26.1565,  0.0000,  7.5303,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 70.24877166748047\n",
      "Output of network:\t tensor([ 1.7035, 26.9937,  2.8828,  0.6868, 18.1307,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 6.0059, 33.6222, 21.5934,  0.0000, 20.9833,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 0.9797490835189819\n",
      "Output of network:\t tensor([1.9798, 0.5900, 0.7299, 0.9578, 0.5900, 7.6452], device='cuda:0')\n",
      "Target Values:\t\t tensor([0.0000, 0.0000, 1.3043, 0.0000, 0.0000, 7.7693], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 17.032814025878906\n",
      "Output of network:\t tensor([ 7.0886, 27.9682,  1.4484, 24.4745, 32.4244, 20.0416], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 4.4151, 30.5162,  0.0000, 28.3491, 39.8941, 23.9976], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 22.595226287841797\n",
      "Output of network:\t tensor([21.3998,  2.4625,  1.0877,  0.8959, 22.3864,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([19.7262, 12.6508,  1.9459,  0.0000, 17.1822,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 2.4988925457000732\n",
      "Output of network:\t tensor([ 2.2982,  0.7248, 21.8850,  2.3311,  1.1976,  1.5753], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000, 20.8949,  0.0000,  0.0000,  0.4187], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 29.03021812438965\n",
      "Output of network:\t tensor([7.4827, 0.9820, 1.8981, 3.5310, 9.3597, 1.9485], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 3.7497,  0.0000,  0.0000, 12.1080, 18.2094,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 3.4303579330444336\n",
      "Output of network:\t tensor([30.5721,  0.6883,  2.3584,  0.5900,  0.7377,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([34.2198,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 10.996511459350586\n",
      "Output of network:\t tensor([20.1388,  2.3397, 19.1861,  0.5900,  2.9565, 25.8105], device='cuda:0')\n",
      "Target Values:\t\t tensor([21.2801,  0.0000, 24.8782,  0.0000,  7.1767, 22.8703], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 27.05657196044922\n",
      "Output of network:\t tensor([44.6897, 21.7784,  0.5900,  2.4228,  7.5005, 15.1853], device='cuda:0')\n",
      "Target Values:\t\t tensor([42.3809, 23.1427,  0.0000,  0.0000,  6.2537, 27.3251], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 2.1466898918151855\n",
      "Output of network:\t tensor([ 0.8624,  4.5271, 20.3715,  0.5900,  1.8863,  0.6736], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  4.0602, 21.9380,  0.0000,  4.8295,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 3.348255157470703\n",
      "Output of network:\t tensor([0.5900, 0.7934, 9.2759, 2.6066, 1.1354, 5.1352], device='cuda:0')\n",
      "Target Values:\t\t tensor([0.0000, 0.0000, 6.1204, 0.0000, 0.0000, 6.1702], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 26.568679809570312\n",
      "Output of network:\t tensor([28.6858,  2.2926, 14.1820, 12.4238, 12.6454,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([22.1028,  1.3325, 24.3033, 15.3749, 14.5576,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 2.4940295219421387\n",
      "Output of network:\t tensor([3.4906, 0.5900, 0.6143, 0.5900, 0.5900, 1.1654], device='cuda:0')\n",
      "Target Values:\t\t tensor([0., 0., 0., 0., 0., 0.], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 1.9032920598983765\n",
      "Output of network:\t tensor([ 0.5900,  0.6411,  0.6440, 24.3093,  0.5900,  0.5900], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  0.0000, 27.3995,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 8.52474308013916\n",
      "Output of network:\t tensor([19.4997,  7.1280,  0.5900,  0.5900, 24.0849], device='cuda:0')\n",
      "Target Values:\t\t tensor([23.9649, 11.6379,  0.0000,  0.0000, 25.3697], device='cuda:0') \n",
      "\n",
      "Test Loss (mean squared error): 2.759573\n",
      "\n",
      "Time: 20.273787260055542\n"
     ]
    }
   ],
   "source": [
    "\"\"\" TESTING OF MODEL \"\"\"\n",
    "\n",
    "# Print out values and images that have large differences in target/value\n",
    "\n",
    "# Track test loss\n",
    "test_loss = 0.0\n",
    "num_predictions = len(test_indices)\n",
    "\n",
    "# Puts model will notify all your layers that you are in eval mode, that way, \n",
    "# batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "model.eval()\n",
    "tarList = list()\n",
    "outList = list()\n",
    "start = time.time()\n",
    "counter = 0\n",
    "# Iterate over test data\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.float(), target.float()\n",
    "        # Move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        output = torch.flatten(output)\n",
    "        # Calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # Update test loss \n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        for tar, out in zip(target, output):\n",
    "            tarList.append(tar.item())\n",
    "            outList.append(out.item())\n",
    "        \n",
    "        if counter < 10:\n",
    "            print(\"test loss from\", counter, \":\", loss.item())\n",
    "            print(\"Output of network:\\t\", output)\n",
    "            print(\"Target Values:\\t\\t\", target,\"\\n\")\n",
    "        \n",
    "        # Example data tensors\n",
    "        if counter < 2:\n",
    "            print(\"loss from this run:\", loss.item())\n",
    "            #print(\"Output of network:\\t\", output)\n",
    "            counterTHIS = 0\n",
    "            for value in output:\n",
    "                counterTHIS += 1\n",
    "                if value.item() > 2.0:\n",
    "                    print(\"Output\", counterTHIS, \":\", value.item())\n",
    "            counterTHIS = 0\n",
    "            for value in target:\n",
    "                counterTHIS += 1\n",
    "                if value.item() > 2.0:\n",
    "                    print(\"Target\", counterTHIS, \":\", value.item())\n",
    "            #print(\"Target Values:\\t\", target,\"\\n\")\n",
    "            counter += 1\n",
    "            # CHECK LOss HEEWRE\n",
    "        \n",
    "\n",
    "\n",
    "    test_loss = test_loss/len(test_loader.sampler)\n",
    "    print('Test Loss (mean squared error): {:.6f}\\n'.format(test_loss))\n",
    "print(f'Time: {time.time()-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: [15.413675308227539, 24.281963348388672, 0.0, 0.0, 0.0, 0.0, 8.667219161987305, 34.57094192504883, 0.0, 0.0, 19.86959457397461, 0.29355934262275696, 27.76616859436035, 42.48615646362305, 2.0097649097442627, 21.378076553344727, 0.0, 8.158004760742188, 1.9989063739776611, 0.0, 0.0, 0.0, 0.0, 0.0, 34.53057098388672, 0.0, 20.81892967224121, 0.0, 8.6765718460083, 0.0, 32.836551666259766, 31.971040725708008, 0.0, 0.0, 0.0, 0.0, 13.380698204040527, 23.09082794189453, 0.0, 0.0, 7.336853504180908, 30.551677703857422, 0.0, 0.0, 0.0, 23.824119567871094, 0.0, 34.6572151184082, 24.6774845123291, 0.0, 2.452630043029785, 5.6244940757751465, 33.50474166870117, 0.0, 0.0, 0.0, 0.0, 8.765008926391602, 7.864948272705078, 0.0, 0.0, 27.3992862701416, 0.0, 0.0, 12.22276496887207, 0.0, 6.766513824462891, 0.0, 0.0, 22.2650203704834, 0.0, 6.583832263946533, 6.77579402923584, 0.0, 9.797807693481445, 28.531536102294922, 25.13006591796875, 27.902179718017578, 28.630016326904297, 11.995145797729492, 8.471881866455078, 0.0, 8.344084739685059, 23.050426483154297, 0.0, 28.96847152709961, 0.0, 0.8175433278083801, 28.52375602722168, 23.564516067504883, 6.868454933166504, 0.0, 33.33180236816406, 16.214649200439453, 0.3290975093841553, 0.0, 22.17304801940918, 0.0, 0.0, 0.0, 28.358001708984375, 0.0, 0.0, 0.0, 0.0, 5.188077926635742, 0.0, 0.0, 28.573713302612305, 0.0, 0.0, 22.563587188720703, 24.89161491394043, 0.0, 0.0, 28.984411239624023, 32.66753005981445, 0.0, 2.207263708114624, 0.0, 0.0, 0.0, 21.450729370117188, 0.0, 1.6722886562347412, 0.0, 18.157833099365234, 0.0, 28.221385955810547, 0.0, 0.0, 0.0, 0.0, 27.068737030029297, 0.0, 0.0, 6.504161834716797, 30.058988571166992, 13.035478591918945, 17.97083282470703, 0.0, 0.0, 0.0, 3.0394480228424072, 0.0, 0.0, 0.0, 25.233484268188477, 13.938126564025879, 44.339176177978516, 13.57684326171875, 0.0, 31.455482482910156, 0.0, 0.0, 0.0, 0.0, 0.0, 1.9801636934280396, 0.0, 0.0, 18.550689697265625, 18.573627471923828, 0.0, 18.57250213623047, 0.0, 0.0, 2.5124213695526123, 0.0, 0.0, 6.685739517211914, 2.687443494796753, 0.0, 34.08469772338867, 0.0, 28.91200065612793, 0.0, 39.92741394042969, 0.0, 8.122030258178711, 15.278162956237793, 0.0, 1.2263150215148926, 0.0, 0.0, 0.0, 0.0, 0.0, 23.606033325195312, 39.8275032043457, 0.0, 4.525550842285156, 19.703737258911133, 0.0, 0.0, 10.057896614074707, 0.0, 10.730697631835938, 1.316390037536621, 0.0, 0.0, 0.0, 17.64693832397461, 0.0, 0.0, 0.0, 5.973076343536377, 0.0, 12.799698829650879, 24.08540153503418, 24.130443572998047, 0.0, 12.106572151184082, 19.872949600219727, 0.0, 0.0, 0.0, 0.0, 0.0, 1.772307276725769, 2.3618266582489014, 1.0633844137191772, 0.0, 5.779498100280762, 0.0, 0.0, 0.0, 0.0, 5.978739261627197, 34.66383361816406, 0.0, 0.0, 18.90934181213379, 16.759855270385742, 5.703260898590088, 0.0, 2.043858289718628, 6.916206359863281, 6.7220330238342285, 1.9371192455291748, 22.221975326538086, 0.0, 24.891849517822266, 12.086301803588867, 13.878555297851562, 0.0, 15.985405921936035, 0.0, 33.097408294677734, 0.0, 0.0, 0.0, 8.852899551391602, 29.6270751953125, 26.170185089111328, 0.0, 11.733464241027832, 23.621688842773438, 0.0, 0.0, 0.4997265934944153, 35.29143142700195, 21.96873664855957, 0.0, 30.0718994140625, 33.96590042114258, 28.360370635986328, 0.0, 8.604140281677246, 0.0, 20.86066246032715, 0.0, 0.0, 30.38807487487793, 24.709171295166016, 9.804241180419922, 0.0, 18.50949478149414, 0.0, 9.38654899597168, 21.54136085510254, 7.808857440948486, 28.076080322265625, 21.57117462158203, 29.4392147064209, 0.0, 10.414888381958008, 7.942117691040039, 0.0, 0.0, 10.781128883361816, 0.0, 26.15582275390625, 17.44538688659668, 0.0, 21.952651977539062, 6.961490154266357, 0.0, 0.0, 1.2952723503112793, 2.025001049041748, 10.454371452331543, 0.0, 20.854822158813477, 0.0, 0.0, 24.68363380432129, 5.58653450012207, 0.0, 20.070871353149414, 26.347549438476562, 0.0, 0.0, 2.7716214656829834, 33.066009521484375, 0.4580780565738678, 0.0, 0.0, 0.0, 1.668516755104065, 0.0, 0.0, 9.93288803100586, 7.283108234405518, 0.2329426258802414, 7.481683731079102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.55474281311035, 13.387128829956055, 0.0, 29.88333511352539, 8.72494125366211, 0.0, 0.0, 28.049970626831055, 20.592496871948242, 0.0, 9.159982681274414, 0.0, 15.436960220336914, 8.257965087890625, 0.0, 0.0, 7.4638214111328125, 9.516477584838867, 0.0, 8.35908317565918, 0.0, 0.0, 14.189241409301758, 0.0, 0.0, 2.2007641792297363, 27.987869262695312, 18.102951049804688, 0.0, 0.0, 16.902414321899414, 25.96209716796875, 0.0, 0.3380802571773529, 0.0, 40.8229866027832, 0.0, 0.0, 4.998159885406494, 0.0, 0.0, 4.005875587463379, 2.2609925270080566, 22.96218490600586, 17.41377830505371, 27.38591766357422, 0.0, 7.54870080947876, 0.0, 8.599679946899414, 23.919755935668945, 0.0, 0.0, 0.0, 36.74042510986328, 0.0, 0.0, 26.356107711791992, 0.0, 3.3975071907043457, 0.0, 17.5484561920166, 12.00388240814209, 0.0, 10.220287322998047, 17.20069122314453, 0.0, 0.0, 0.0, 1.9750980138778687, 0.0, 0.7020290493965149, 0.0, 0.0, 17.586116790771484, 0.0, 7.255958557128906, 23.22137451171875, 0.0, 35.453529357910156, 18.027099609375, 0.0, 0.0, 15.336837768554688, 0.0, 8.84818172454834, 0.0, 0.0, 0.0, 13.007190704345703, 0.0, 0.0, 23.046659469604492, 0.0, 2.2903902530670166, 22.231334686279297, 0.0, 0.0, 0.0, 0.0, 0.0, 6.843653202056885, 0.0, 0.0, 0.0, 0.0, 29.185749053955078, 20.1151180267334, 0.0, 6.765270233154297, 17.756282806396484, 0.0, 0.0, 0.0, 0.0, 0.0, 7.795260906219482, 0.0, 1.9661258459091187, 20.84941864013672, 26.927593231201172, 32.94750213623047, 10.3045072555542, 0.0, 8.112415313720703, 0.0, 0.0, 12.289867401123047, 0.0, 0.0, 0.0, 22.267711639404297, 6.065673828125, 28.868257522583008, 4.346270561218262, 0.0, 28.926101684570312, 1.2016018629074097, 0.0, 0.0, 0.0, 32.522891998291016, 14.523200035095215, 0.0, 0.0, 0.0, 0.0, 0.0, 13.462956428527832, 0.0, 10.290528297424316, 0.0, 31.542266845703125, 0.0, 36.2327766418457, 4.023519992828369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.16048049926758, 35.1356086730957, 0.0, 1.397655725479126, 22.874303817749023, 26.156476974487305, 0.0, 7.530344009399414, 0.0, 6.005949974060059, 33.62224578857422, 21.593412399291992, 0.0, 20.98329734802246, 0.0, 0.0, 0.0, 1.3042645454406738, 0.0, 0.0, 7.769343376159668, 4.415075778961182, 30.5162296295166, 0.0, 28.349140167236328, 39.89411163330078, 23.997570037841797, 19.72622299194336, 12.650750160217285, 1.9458931684494019, 0.0, 17.18218421936035, 0.0, 0.0, 0.0, 20.894941329956055, 0.0, 0.0, 0.41873690485954285, 3.7496628761291504, 0.0, 0.0, 12.10800838470459, 18.20942497253418, 0.0, 34.219844818115234, 0.0, 0.0, 0.0, 0.0, 0.0, 21.28010368347168, 0.0, 24.878196716308594, 0.0, 7.176665306091309, 22.87030792236328, 42.38090515136719, 23.14272689819336, 0.0, 0.0, 6.253695964813232, 27.325115203857422, 0.0, 4.060182094573975, 21.937992095947266, 0.0, 4.8295464515686035, 0.0, 0.0, 0.0, 6.120373249053955, 0.0, 0.0, 6.170167446136475, 22.102758407592773, 1.332477331161499, 24.303281784057617, 15.374920845031738, 14.557612419128418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.399534225463867, 0.0, 0.0, 23.964853286743164, 11.63792896270752, 0.0, 0.0, 25.36969757080078]\n",
      "Outputs [16.903270721435547, 26.72953224182129, 0.5899884700775146, 0.5899884700775146, 0.5899884700775146, 0.5899884700775146, 6.610044479370117, 33.1317138671875, 0.5899884700775146, 0.9930721521377563, 28.531841278076172, 1.2045061588287354, 24.089601516723633, 32.13121032714844, 3.065183162689209, 16.305025100708008, 0.5899884700775146, 1.8234264850616455, 1.6443504095077515, 1.1262073516845703, 0.5899884700775146, 0.5899884700775146, 1.0088410377502441, 1.6443504095077515, 23.791284561157227, 0.5899884700775146, 24.34600257873535, 0.5899884700775146, 6.576841354370117, 0.5899884700775146, 26.687368392944336, 25.37688636779785, 0.5899884700775146, 0.7208335995674133, 1.3174824714660645, 0.5899884700775146, 2.1649913787841797, 25.323209762573242, 3.4381051063537598, 0.879857063293457, 16.455772399902344, 25.321107864379883, 0.5899884700775146, 0.5899884700775146, 0.5899884700775146, 19.504873275756836, 0.6483657956123352, 22.42595100402832, 22.062023162841797, 0.80250084400177, 1.7871330976486206, 1.8814582824707031, 25.922466278076172, 0.5899884700775146, 2.4227592945098877, 0.7200814485549927, 0.8062046766281128, 2.9207944869995117, 20.297649383544922, 0.6685497164726257, 1.5489249229431152, 19.846593856811523, 3.716590166091919, 0.5899884700775146, 16.455772399902344, 0.5899884700775146, 7.500500679016113, 1.1914024353027344, 0.5899884700775146, 21.165145874023438, 0.6722687482833862, 4.063723564147949, 2.3080344200134277, 0.5899884700775146, 13.491418838500977, 20.16520881652832, 24.03062629699707, 26.394847869873047, 30.754961013793945, 3.6350228786468506, 6.610044479370117, 1.9421099424362183, 5.317975044250488, 21.236385345458984, 0.5899884700775146, 18.526514053344727, 3.0163989067077637, 2.5498833656311035, 20.687522888183594, 24.693973541259766, 6.818222999572754, 0.5899884700775146, 23.261899948120117, 14.717864036560059, 2.358398914337158, 2.841766595840454, 9.393001556396484, 0.5899884700775146, 0.835429310798645, 0.5899884700775146, 25.412824630737305, 0.5899884700775146, 0.6343706846237183, 0.5899884700775146, 0.6605648398399353, 4.185582160949707, 1.8637384176254272, 0.5899884700775146, 26.890586853027344, 0.7336385250091553, 1.294308066368103, 18.123516082763672, 25.038082122802734, 0.5899884700775146, 1.9697898626327515, 26.928207397460938, 19.924835205078125, 0.6160304546356201, 1.6010582447052002, 0.5899884700775146, 0.5899884700775146, 3.716590166091919, 15.383710861206055, 1.6561846733093262, 1.1170356273651123, 0.6021648645401001, 24.197084426879883, 0.5899884700775146, 24.017242431640625, 0.5899884700775146, 0.5899884700775146, 1.5668684244155884, 0.695364236831665, 26.897937774658203, 1.2128164768218994, 0.5899884700775146, 3.443190574645996, 27.339223861694336, 15.483367919921875, 7.3201904296875, 1.8480021953582764, 0.5899884700775146, 0.5899884700775146, 2.0178322792053223, 0.5899884700775146, 0.5899884700775146, 0.6233323812484741, 22.010168075561523, 11.6668701171875, 35.19840621948242, 13.836027145385742, 0.5899884700775146, 17.092161178588867, 1.0516867637634277, 0.9000464677810669, 0.5899884700775146, 2.2581450939178467, 2.280499219894409, 4.527650833129883, 0.5899884700775146, 4.301244258880615, 2.3989901542663574, 8.448525428771973, 0.5899884700775146, 12.650644302368164, 2.1845333576202393, 1.26161789894104, 1.8278520107269287, 0.5899884700775146, 0.8054431676864624, 24.619230270385742, 3.378720283508301, 1.675513505935669, 27.30057716369629, 2.504502296447754, 18.26078224182129, 0.5899884700775146, 26.844505310058594, 0.5899884700775146, 9.878908157348633, 17.134923934936523, 0.6417986154556274, 2.4910922050476074, 2.4551632404327393, 0.5899884700775146, 1.0998897552490234, 0.5899884700775146, 0.5899884700775146, 22.93255043029785, 34.692317962646484, 0.5899884700775146, 1.248272180557251, 8.448525428771973, 0.5899884700775146, 0.6006765365600586, 9.878908157348633, 2.379039764404297, 16.847034454345703, 2.6465587615966797, 0.5899884700775146, 1.403841495513916, 0.5899884700775146, 10.490935325622559, 0.5899884700775146, 0.5899884700775146, 0.5899884700775146, 1.5149657726287842, 1.342576265335083, 8.73647689819336, 4.539914131164551, 23.830284118652344, 1.6215760707855225, 14.534754753112793, 7.181598663330078, 0.7355788946151733, 3.0593421459198, 0.5899884700775146, 0.5899884700775146, 0.8455514907836914, 0.785795271396637, 2.0025157928466797, 0.826173722743988, 0.5902429819107056, 6.466757774353027, 0.8625283241271973, 0.5899884700775146, 1.5037102699279785, 0.9500758647918701, 3.561915636062622, 31.892515182495117, 0.5899884700775146, 0.6831482648849487, 19.592790603637695, 20.433568954467773, 6.154401779174805, 2.744758367538452, 1.9411534070968628, 8.452775001525879, 3.4824516773223877, 4.374238014221191, 30.045513153076172, 0.5899884700775146, 14.510123252868652, 5.451600074768066, 9.034936904907227, 3.2010676860809326, 13.836027145385742, 4.818119049072266, 31.892515182495117, 0.5899884700775146, 1.1262073516845703, 1.4596667289733887, 5.451600074768066, 35.69182586669922, 25.250581741333008, 1.2864538431167603, 12.294159889221191, 15.322598457336426, 1.8980695009231567, 0.8515294790267944, 0.9000464677810669, 28.074481964111328, 21.68625259399414, 0.5899884700775146, 26.629520416259766, 31.115453720092773, 19.572553634643555, 0.5899884700775146, 16.660415649414062, 0.5899884700775146, 8.109516143798828, 1.0998897552490234, 0.5899884700775146, 24.874210357666016, 24.237730026245117, 9.234291076660156, 0.5899884700775146, 16.182680130004883, 0.9904216527938843, 12.892127990722656, 19.35184097290039, 5.190339088439941, 28.109233856201172, 22.230602264404297, 27.272794723510742, 0.5899884700775146, 17.144254684448242, 8.586176872253418, 0.5899884700775146, 0.6993396878242493, 3.7159366607666016, 0.5899884700775146, 25.889524459838867, 15.871439933776855, 1.8272932767868042, 15.567834854125977, 4.2488694190979, 0.5899884700775146, 0.5899884700775146, 6.4201507568359375, 4.800352096557617, 2.1649913787841797, 0.5899884700775146, 19.676523208618164, 0.5899884700775146, 0.5899884700775146, 14.253071784973145, 6.466757774353027, 0.5899884700775146, 5.687740325927734, 24.350292205810547, 0.5899884700775146, 5.058327674865723, 3.0987160205841064, 26.210561752319336, 6.41463565826416, 1.403841495513916, 0.5899884700775146, 0.5899884700775146, 6.785872459411621, 0.5899884700775146, 0.806813657283783, 8.633842468261719, 7.482693672180176, 1.403841495513916, 6.46875, 1.2384865283966064, 0.9606108069419861, 0.5899884700775146, 1.8914295434951782, 0.5899884700775146, 0.5899884700775146, 0.5899884700775146, 17.679553985595703, 12.249431610107422, 0.6982064247131348, 28.197757720947266, 9.490788459777832, 0.5899884700775146, 2.014375686645508, 19.437963485717773, 19.592790603637695, 0.5998923182487488, 10.263396263122559, 0.5899884700775146, 11.6668701171875, 7.908502578735352, 0.5899884700775146, 0.5899884700775146, 9.2283935546875, 9.74917221069336, 2.841766595840454, 2.976526975631714, 0.6056763529777527, 0.5899884700775146, 10.417717933654785, 4.750340461730957, 0.5899884700775146, 5.778311729431152, 12.100960731506348, 17.241687774658203, 0.5899884700775146, 2.2546753883361816, 21.91736602783203, 21.722179412841797, 0.5899884700775146, 2.014375686645508, 1.880400538444519, 35.51087951660156, 0.5899884700775146, 2.047792434692383, 7.527575492858887, 0.5899884700775146, 3.929635763168335, 8.300222396850586, 1.9849787950515747, 19.08157730102539, 14.648279190063477, 31.029172897338867, 1.1622579097747803, 12.690942764282227, 0.5899884700775146, 19.957984924316406, 24.648365020751953, 0.5899884700775146, 0.5899884700775146, 1.9697898626327515, 33.167022705078125, 0.5899884700775146, 0.6189783811569214, 28.360065460205078, 0.5899884700775146, 5.82668399810791, 1.1191965341567993, 17.56488609313965, 9.597918510437012, 1.5683207511901855, 8.29092025756836, 14.638404846191406, 1.069633960723877, 3.5807831287384033, 0.5899884700775146, 1.1614511013031006, 0.7431087493896484, 0.6078056693077087, 0.6453465819358826, 0.5899884700775146, 25.98303985595703, 0.5899884700775146, 1.735825538635254, 20.116119384765625, 0.5899884700775146, 36.48210906982422, 11.833654403686523, 1.0965838432312012, 3.195699691772461, 17.86113739013672, 0.5899884700775146, 10.2860689163208, 2.3382952213287354, 0.7530611753463745, 0.7238689661026001, 20.297649383544922, 1.1614511013031006, 0.5899884700775146, 26.30146598815918, 0.5899884700775146, 1.7832674980163574, 21.78022003173828, 0.5899884700775146, 2.165112018585205, 0.5899884700775146, 1.2406587600708008, 1.1310651302337646, 5.333037376403809, 0.5899884700775146, 0.5998923182487488, 0.5899884700775146, 0.5899884700775146, 23.336397171020508, 16.95772933959961, 0.5899884700775146, 3.4824516773223877, 25.80645179748535, 0.5899884700775146, 4.814884185791016, 0.6378832459449768, 0.6284157633781433, 1.1926740407943726, 4.304729461669922, 0.6798967719078064, 1.4661823511123657, 21.236385345458984, 21.399845123291016, 21.825613021850586, 2.7185401916503906, 0.5899884700775146, 6.800636291503906, 0.9192773699760437, 0.5899884700775146, 12.892127990722656, 0.6606103777885437, 0.8725981116294861, 0.5921951532363892, 19.011669158935547, 4.231006622314453, 28.925134658813477, 5.28034782409668, 3.800248384475708, 24.448450088500977, 0.8508114814758301, 0.593720018863678, 0.8546899557113647, 0.5899884700775146, 25.47589874267578, 2.345747947692871, 2.5825886726379395, 0.5899884700775146, 1.6295379400253296, 0.5899884700775146, 0.6380578875541687, 10.177289962768555, 0.5899884700775146, 15.317797660827637, 0.6186699271202087, 33.1317138671875, 0.5899884700775146, 29.167940139770508, 4.421009063720703, 0.5899884700775146, 2.2231178283691406, 1.448391318321228, 1.5716066360473633, 0.5899884700775146, 0.5899884700775146, 35.547786712646484, 27.407556533813477, 0.5899884700775146, 2.1616179943084717, 16.52964973449707, 18.30175018310547, 0.5899884700775146, 5.921923637390137, 0.5899884700775146, 1.7035499811172485, 26.99370765686035, 2.882797956466675, 0.6867944002151489, 18.13065528869629, 0.5899884700775146, 1.9797837734222412, 0.5899884700775146, 0.7298892736434937, 0.9578404426574707, 0.5899884700775146, 7.645196914672852, 7.088553428649902, 27.96818733215332, 1.448391318321228, 24.4744930267334, 32.42443084716797, 20.04155921936035, 21.399845123291016, 2.4625496864318848, 1.0877149105072021, 0.895850658416748, 22.386396408081055, 0.5899884700775146, 2.2982492446899414, 0.7248485088348389, 21.88495445251465, 2.3310718536376953, 1.1976019144058228, 1.575338363647461, 7.482693672180176, 0.9820209741592407, 1.8980695009231567, 3.5309956073760986, 9.359731674194336, 1.948466420173645, 30.572114944458008, 0.6883350610733032, 2.358398914337158, 0.5899884700775146, 0.7376929521560669, 0.5899884700775146, 20.13882827758789, 2.3396663665771484, 19.186065673828125, 0.5899884700775146, 2.9565346240997314, 25.81047248840332, 44.68973922729492, 21.778400421142578, 0.5899884700775146, 2.4227592945098877, 7.500500679016113, 15.185306549072266, 0.862423300743103, 4.527115821838379, 20.371461868286133, 0.5899884700775146, 1.8863368034362793, 0.6736104488372803, 0.5899884700775146, 0.7934188842773438, 9.275915145874023, 2.6065964698791504, 1.1353602409362793, 5.135228157043457, 28.685794830322266, 2.2925779819488525, 14.181997299194336, 12.423824310302734, 12.64542293548584, 0.5899884700775146, 3.490631341934204, 0.5899884700775146, 0.6142565608024597, 0.5899884700775146, 0.5899884700775146, 1.1653755903244019, 0.5899884700775146, 0.6410640478134155, 0.6439787149429321, 24.309255599975586, 0.5899884700775146, 0.5899884700775146, 19.499725341796875, 7.127991676330566, 0.5899884700775146, 0.5899884700775146, 24.08492660522461]\n"
     ]
    }
   ],
   "source": [
    "print(\"Targets:\",tarList)\n",
    "print(\"Outputs\",outList)\n",
    "os.chdir(startingDir)\n",
    "titlesTestData = [\"targets\",\"outputs\"]\n",
    "testFileStats = \"test_data_\" + month +\".csv\"\n",
    "print(trainFileStats)\n",
    "with open(testFileStats,'w',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(titlesTrainingData)\n",
    "    for target, output in zip(tarList, outList):\n",
    "        writer.writerow([target,output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "test loss from 0 : 8.705543518066406\n",
      "Output of network:\t tensor([12.8590, 15.7529, -0.3846, 12.2453,  9.3890,  4.3938,  2.5041, 24.0620,\n",
      "        28.4192,  1.5286, 12.6894, 26.6492, 22.8743,  0.9076,  1.4365, -0.0561,\n",
      "         1.4544,  1.8497, 27.9742,  2.8806,  2.1493, 38.4997, 14.5286,  0.3495,\n",
      "        25.0275, 28.5833,  0.9340,  1.0857, 12.7810,  0.6429, 21.6899,  0.4041,\n",
      "        14.1196,  5.7087,  1.1327,  1.4717,  5.4660,  0.6382, 15.6079,  0.6562,\n",
      "         0.2129, 19.7411, 14.8339, 10.6008,  0.9039,  0.7554, 26.4753,  0.6610,\n",
      "         0.7440,  2.2295, -0.2550,  1.0393, 12.0048,  1.5124,  0.5966,  5.7378,\n",
      "        20.1925,  9.6816, 24.3721, 12.1435], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 8.8612, 13.8704,  0.0000, 14.0826, 16.7069,  9.9999,  3.4293, 27.1545,\n",
      "        30.5333,  0.0000, 15.6925, 29.5445, 17.7824,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, 25.2060,  2.0798,  0.0000, 38.5423, 16.9126,  0.0000,\n",
      "        16.4176, 29.5312,  0.3041,  0.0000, 12.5302,  0.0000, 24.8735,  0.0000,\n",
      "        17.3701, 11.4069,  0.0000,  0.0000, 10.6400,  0.0000, 18.6133,  1.3700,\n",
      "         0.0000, 19.7065, 11.1615, 11.7912,  0.0000,  0.0000, 24.8396,  0.0000,\n",
      "         0.0000,  7.3082,  0.0000,  0.0000,  7.7832,  0.0000,  0.0000,  6.3207,\n",
      "        11.6752, 10.5683, 21.4631, 14.6868], device='cuda:0') \n",
      "\n",
      "test loss from 1 : 19.2954044342041\n",
      "Output of network:\t tensor([-2.0958e-01,  5.8459e+00,  1.0143e+00,  7.1632e+00,  4.8022e+00,\n",
      "         3.2162e+01, -1.6499e-01,  4.1955e+00,  2.1321e+01,  1.7452e+00,\n",
      "         2.0499e+01,  2.2804e+01,  1.4962e+00,  1.6939e+01,  4.2155e-01,\n",
      "         5.8438e-01,  2.2087e+01,  8.6865e+00,  2.9166e+00, -5.0487e-02,\n",
      "         1.9322e+01,  1.1800e+01,  6.8342e+00,  2.1047e+01,  5.2732e-01,\n",
      "         1.1598e+01,  7.1677e-01,  7.3235e+00,  6.1871e-01,  6.5771e+00,\n",
      "         2.8177e-01, -3.0924e-02,  1.7211e+00,  2.8851e+01,  2.8747e+01,\n",
      "         2.1755e+01,  3.6909e+00,  6.9330e-01,  1.2713e+01,  1.7410e+00,\n",
      "         4.7987e-01,  1.2137e-01,  1.5661e+00,  5.2084e+00,  1.3335e+00,\n",
      "         2.4213e+01,  1.6177e+01,  4.3340e-01,  2.3508e+01,  7.7845e-01,\n",
      "         2.1756e+01,  1.0075e+01,  3.2186e+01,  9.4386e-02,  6.3110e-01,\n",
      "         2.0361e+01,  8.5444e+00, -2.5540e-01,  1.5612e+00,  2.3965e+01],\n",
      "       device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  8.8836,  0.0000,  3.9808,  0.0000, 35.3616,  0.0000,  8.7341,\n",
      "        18.8295,  0.0000,  4.9553, 23.4208,  0.0000, 21.5092,  0.0000,  0.0000,\n",
      "        24.8610,  9.5255,  2.5500,  0.0000, 23.5689, 17.3183, 19.7555, 15.2632,\n",
      "         0.0000, 17.8977,  0.0000, 10.4797,  0.0000,  2.3082,  0.0000,  0.0000,\n",
      "         0.0000, 24.6775, 26.0920, 21.3098, 15.4230,  0.0000,  7.2828,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  6.9969,  0.0000, 26.4705, 17.4570,  0.0000,\n",
      "        34.9331,  0.0000, 15.9750, 14.6657, 36.8551,  0.0000,  0.0000, 22.8363,\n",
      "        10.6708,  0.0000,  0.0000, 30.8990], device='cuda:0') \n",
      "\n",
      "test loss from 2 : 10.496196746826172\n",
      "Output of network:\t tensor([ 0.2734, 29.1792, 10.5311,  7.6476, 23.0202,  0.9171,  9.0765, 24.5003,\n",
      "        -0.1138,  0.8546,  6.5444, 25.4357, 26.7582,  1.0861, 16.7849, 13.2328,\n",
      "         0.4852, 17.3631,  2.0132,  1.7549,  0.7461,  0.0931, 13.1431,  8.1630,\n",
      "        17.0981, 25.9824,  1.1004,  3.5098,  0.3564, 23.0672,  0.1343,  1.7985,\n",
      "        18.5041,  7.5597, 16.9434,  0.6883,  1.9616,  0.8367, 30.0440,  3.4298,\n",
      "         0.6017, 24.5779,  1.4094,  0.5056,  1.1673,  9.1705,  1.6822,  0.8917,\n",
      "        15.1187,  1.2500,  1.0251,  0.3856,  0.8574, 26.4744,  1.0751,  6.6365,\n",
      "        20.3987,  3.2248,  1.5105, -0.1274], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000, 30.3332, 12.7003,  8.8241, 28.1160,  0.0000, 11.6962, 24.7370,\n",
      "         0.0000,  0.0000,  1.0218, 27.6596, 16.2146,  0.0000, 17.5418, 12.8928,\n",
      "         0.0000, 24.4852,  0.0000,  0.2876,  0.0000,  0.0000, 14.9423,  4.9714,\n",
      "        23.5549, 35.8561,  0.0000,  3.6860,  0.0000, 27.5434,  0.0000,  0.0000,\n",
      "        18.4218, 11.1464, 15.5024,  0.0000,  0.0000,  0.0000, 32.9471,  1.8823,\n",
      "         0.0000, 27.8203,  0.0000,  0.0000,  0.0000, 12.8780,  6.5691,  0.0000,\n",
      "        14.9092,  0.0000,  0.0000,  0.0000,  0.0000, 22.6217,  0.0000, 16.0596,\n",
      "        17.1985,  4.1097,  0.3859,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 3 : 12.788207054138184\n",
      "Output of network:\t tensor([ 2.8274,  0.8007, 22.7725, 20.3148,  1.8042,  0.2483,  0.1963,  0.0913,\n",
      "         9.2577,  3.2375, 21.2623,  0.9424,  1.4232, -0.0362,  1.0688, 13.6546,\n",
      "        17.5111,  0.0604, 15.8413,  1.3606,  3.6964,  2.8575, 14.5004,  0.8636,\n",
      "         0.6080,  1.9463,  0.7398,  2.7951,  6.9782,  0.3348,  0.3065,  1.5154,\n",
      "        24.7812, 16.6861,  1.5686, 25.6181, 21.4403,  2.2357, -0.1252,  1.1134,\n",
      "        31.7707,  0.0528, 18.8218,  0.7275,  5.2120,  5.2083, 20.1649,  0.0837,\n",
      "         1.2951, 29.6354,  0.4323,  1.1300,  3.0348, 22.6236,  4.6500,  0.5654,\n",
      "         4.5644, 24.4027,  0.4916,  0.6303], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000, 27.3509, 20.7218,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         7.0335,  0.0000, 20.8146,  0.0000,  0.0000,  0.0000,  0.0000, 18.9435,\n",
      "        17.1624,  0.0000, 16.0435,  0.0000,  3.9912,  0.4020, 16.9740,  0.0000,\n",
      "         0.0000,  6.6065,  0.0000,  8.8143, 12.4586,  0.0000,  0.0000,  3.6128,\n",
      "        24.4785, 20.2865,  0.0000, 28.2208,  8.5541,  0.0000,  0.0000,  0.0000,\n",
      "        26.0233,  0.0000, 20.8026,  0.0000, 12.3931,  0.0000, 29.9679,  0.0000,\n",
      "         0.0571, 31.1037,  0.0000,  0.0000,  4.7707, 23.4603,  3.5322,  0.0000,\n",
      "         5.5860, 14.6444,  8.4928,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 4 : 24.483806610107422\n",
      "Output of network:\t tensor([-0.6132,  4.4792,  2.5046,  1.3141,  1.3654,  0.3290, -0.1378,  0.3125,\n",
      "        20.3119, 18.9050, 22.2246,  1.9696, 20.5508, 27.3779, 17.2524, 15.0465,\n",
      "        31.2526,  4.1026,  9.4269,  0.7494,  2.0180, 18.6946,  3.3630,  3.3052,\n",
      "        14.9214,  4.1877, 24.5331, 15.4554, -0.3697,  0.2900,  0.5441,  0.0332,\n",
      "         0.6320,  1.1954,  3.1088,  0.3125,  7.9123,  1.6731,  1.6525, 23.5415,\n",
      "        -0.0559,  4.2173,  6.5681, 20.8453,  2.7348, 14.0539,  0.9795,  0.1389,\n",
      "        19.7325, 30.3309,  2.3288,  1.8055, -0.3422, 12.4571,  0.1698, 17.7040,\n",
      "         1.4045, -0.0969, 30.5629,  3.1187], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        18.6537, 20.8849, 42.4520,  7.0393, 23.0453, 22.6090, 20.0027, 16.0287,\n",
      "        33.2862,  2.6317, 18.0532,  0.0000,  0.0000, 20.0875,  0.0000,  7.0383,\n",
      "        31.7541,  1.9625, 21.5845, 20.0222,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, 12.1533,  3.2195,  0.0000, 23.5890,\n",
      "         0.0000,  2.7716,  8.5894, 38.0756,  0.0000, 18.3873,  0.0000,  0.0000,\n",
      "        23.2249, 36.8842,  0.0000,  0.0000,  0.0000,  3.7744,  0.0000, 21.5712,\n",
      "         0.0000,  0.0000, 28.2606,  1.7068], device='cuda:0') \n",
      "\n",
      "test loss from 5 : 11.583172798156738\n",
      "Output of network:\t tensor([25.9391,  1.4711,  1.5509,  1.0903,  0.8451,  1.5750,  0.9258,  1.0597,\n",
      "         0.1332,  1.5078,  8.1424,  3.9436,  5.2426,  0.1681, 31.8813,  3.7565,\n",
      "        21.1010,  0.5021, 21.1652, 16.6290,  2.5268, 21.2459,  1.4284, 20.1576,\n",
      "         1.1873,  0.6346, 16.0454, 21.5749,  2.6325,  0.2068, 22.3933, 22.9409,\n",
      "         1.8109,  9.4814,  2.2726,  4.6595, 24.2114,  1.1973,  9.3890,  0.9737,\n",
      "         0.3817,  3.2877,  0.5077,  1.5691, 25.3746, -0.2510, 28.7341,  2.0958,\n",
      "        24.1164, 32.0965,  0.7170, 34.4629, 19.9223, 14.5996,  1.2119,  3.9284,\n",
      "        -0.0782,  7.0965, 25.5264,  6.4848], device='cuda:0')\n",
      "Target Values:\t\t tensor([32.5708,  3.9615,  2.5529,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  1.2150,  9.4160,  5.4666, 13.2754,  0.0000, 36.7404,  0.3302,\n",
      "        26.5250,  0.2809, 22.9336, 19.3509,  3.9371, 15.4149, 10.4801, 23.4072,\n",
      "         0.0000,  0.0000, 15.1465, 24.6982,  3.2024,  0.0000, 29.2334, 24.6838,\n",
      "         0.0000,  9.3100,  0.0000,  9.8905, 25.6671,  0.0000,  6.6951,  0.0000,\n",
      "         0.0000,  3.9883,  0.0000,  0.0000, 22.3201,  0.0000, 24.2257,  0.0000,\n",
      "        23.9998, 26.5196,  0.2127, 41.5678, 21.7133, 16.0887,  3.4928,  0.0000,\n",
      "         0.0000, 16.4062, 25.5163, 11.2581], device='cuda:0') \n",
      "\n",
      "test loss from 6 : 13.554101943969727\n",
      "Output of network:\t tensor([22.2246,  6.0470, 21.7611, 27.4144,  2.6340,  2.2164, 18.9301, 25.2858,\n",
      "         0.7107,  0.4372,  0.9210,  3.9535, 18.2637,  0.3961,  0.6879, 28.7474,\n",
      "         0.6347, 15.7088,  0.2770, 24.3999, -0.6282,  0.0298,  1.0523, -1.1279,\n",
      "        16.1600,  0.3795,  1.9632,  0.8288, 19.0213,  2.5543, 26.4818,  1.0209,\n",
      "        26.9810,  0.2932,  3.7189,  0.3173,  1.2918, 20.3049, -0.2841, 26.5941,\n",
      "         0.8347,  0.5170,  0.0850,  7.9953,  7.1982, 19.3707, 20.3310,  0.1957,\n",
      "         2.7315, 13.7008, 22.0937, 16.0796, -0.0333,  1.6782, 16.1911, 27.9657,\n",
      "        20.2500,  4.4978,  1.5055, -0.1137], device='cuda:0')\n",
      "Target Values:\t\t tensor([22.2571, 12.2480, 26.6621, 30.1222,  0.0000,  0.0000, 27.6280, 23.9268,\n",
      "         0.0000,  0.0000,  0.0000,  4.0756, 16.6665,  0.0000,  0.0000, 25.7475,\n",
      "         0.0000, 21.4920,  0.0000, 26.1588,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        11.4460,  0.0000,  0.0000,  0.0000, 20.4960,  0.0000, 28.7621,  0.0000,\n",
      "        34.9031,  0.0000,  3.0475,  0.0000,  0.0000, 23.5786,  0.0000, 31.6879,\n",
      "         0.0000,  0.0000,  0.0000, 15.6044,  1.3522, 19.5220, 26.9254,  0.0000,\n",
      "         0.0000, 16.4842, 22.3679, 20.1161,  0.0000,  1.3970, 16.3637, 44.0830,\n",
      "        22.7685,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 7 : 12.913476943969727\n",
      "Output of network:\t tensor([ 1.9461e+01,  8.6911e-01,  1.8497e+01,  9.6847e-01,  2.5832e+00,\n",
      "         1.9610e+01,  6.5421e+00,  2.2988e+01,  9.5301e-01,  2.1243e+01,\n",
      "         2.5473e+01,  8.2382e-01,  1.9737e+01,  1.8964e+00, -1.0241e-01,\n",
      "         4.7249e+00,  1.6065e+01,  2.5643e+00,  1.2783e+01,  3.0110e+01,\n",
      "         3.6653e+00,  2.5169e-01,  6.3554e-01,  2.0451e+00, -1.5747e-02,\n",
      "         2.0079e+01,  2.9537e+01,  1.1748e+00,  2.4377e+01,  2.4387e+01,\n",
      "         9.7435e+00,  1.5192e+01,  4.5119e+00,  2.7813e-01,  1.0324e-01,\n",
      "         2.2461e+00,  1.4191e+00,  1.9347e+01,  6.3877e-01,  1.0215e+00,\n",
      "         1.8447e+01,  5.3009e-01,  1.4770e+00,  6.7771e+00,  1.6376e+01,\n",
      "         5.1839e-01,  5.8451e+00,  2.1807e-01,  4.5614e-01, -3.9300e-01,\n",
      "         9.9814e-01,  1.5096e+00,  3.9365e+00,  8.2083e-01,  1.0480e+00,\n",
      "         4.7754e-01,  3.9141e+00,  6.2859e-01,  1.5373e-01,  1.3022e+00],\n",
      "       device='cuda:0')\n",
      "Target Values:\t\t tensor([21.3546,  0.0000, 23.3385,  0.0000,  0.0000, 19.8620,  7.0483, 17.4719,\n",
      "         0.0000, 18.1507, 36.8295,  0.0000, 17.0595,  0.0000,  0.0000,  9.9213,\n",
      "        16.9256,  0.4880, 10.9727, 25.4200,  5.2127,  0.0000,  0.0000,  7.8973,\n",
      "         0.0000, 25.0267, 32.9778,  0.0000, 26.4203, 28.0106,  8.5298, 14.7567,\n",
      "         5.3239,  0.0000,  0.0000,  6.6921,  1.9009, 22.9074,  0.0000,  0.0000,\n",
      "        17.9064,  0.0000,  0.0000,  0.7110, 13.3438,  0.0000,  4.8280,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  2.7692,  0.0000,  0.0000,  0.0000,\n",
      "        21.5934,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 8 : 17.5146484375\n",
      "Output of network:\t tensor([ 1.1547e+00,  6.4469e-01,  7.1847e-01,  1.3015e+01,  3.0730e+00,\n",
      "         5.6287e-01,  2.8638e+01,  1.9760e+01, -7.4315e-01,  4.0493e-01,\n",
      "         1.7152e+01,  8.0663e-01,  6.7500e-01,  1.8639e+00,  1.1879e+00,\n",
      "         2.1842e+01,  2.2551e+01,  2.9274e-01,  2.1970e+01,  2.5559e+00,\n",
      "         2.5473e+00,  4.0686e-01,  2.2220e+01,  1.4582e+00,  1.6157e+01,\n",
      "         8.4276e-01,  8.6917e-02,  1.8685e+01,  1.9430e+01,  5.2185e-01,\n",
      "         2.4072e+01,  1.3880e+00,  7.2376e-02,  1.8958e+01,  3.3833e+01,\n",
      "        -3.2597e-02,  2.7622e+00,  4.8847e+00,  1.0169e+01,  1.0324e-01,\n",
      "         1.7535e+01,  1.0364e+00,  2.0061e+01,  2.3304e+01,  1.8160e+00,\n",
      "         1.2028e+01,  2.6264e+01,  2.1584e+01,  3.4352e+01,  2.3442e+01,\n",
      "         1.4229e-02,  8.9025e-01,  9.0412e-01,  8.6122e-01,  1.3424e+01,\n",
      "         6.6600e-01,  7.1298e-01, -7.4315e-01,  4.0831e+00,  9.3119e-02],\n",
      "       device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  0.0000,  0.0000, 16.2606,  0.0000,  0.0000, 33.7366, 17.6511,\n",
      "         0.0000,  0.0000, 18.4145,  0.0000,  0.0000,  0.0000,  0.2900, 25.7826,\n",
      "        22.1670,  0.0000, 21.7065,  6.0708,  0.0000,  0.0000, 23.7122,  0.3803,\n",
      "        15.8627,  0.0000,  0.0000, 17.6050, 17.8503,  0.0000, 24.7318,  1.2395,\n",
      "         0.0000, 24.8604, 38.0996,  0.0000,  0.0000, 13.5791,  7.3344,  0.0000,\n",
      "        16.3223,  0.0000, 27.7638, 28.1983,  0.0000,  9.7382, 20.9213, 22.3828,\n",
      "        36.2873, 31.1309,  0.0000,  0.0000,  0.0000,  0.0000, 37.8266,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0') \n",
      "\n",
      "test loss from 9 : 13.379350662231445\n",
      "Output of network:\t tensor([ 0.4738,  2.0242,  2.1891,  1.7397,  0.6540, 15.1079,  9.5563,  2.2610,\n",
      "         8.8533,  1.4498,  1.9822,  0.5410,  2.4385, -0.2734, 30.5359,  1.1825,\n",
      "        30.2123, -0.2430,  0.4738, 35.0850, -0.1096, 20.0114,  0.5589, 21.7060,\n",
      "        32.3497,  3.3175,  7.1785,  4.1027,  1.6175,  1.5194,  0.7291, 13.2052,\n",
      "         0.3466,  6.7929,  2.2619, 15.3283, 14.5004,  2.5940,  2.9194,  0.5937,\n",
      "         9.2813, -0.6042, 23.9158,  0.0380,  0.3510, -0.2696, 31.3495,  0.1774,\n",
      "         0.8865, 23.3035, 29.2256, -0.2221,  1.2532,  0.5136, 13.8786,  4.6375,\n",
      "        11.2912,  8.6069, 11.4064, 33.1026], device='cuda:0')\n",
      "Target Values:\t\t tensor([ 0.0000,  2.3020,  0.0000,  4.0143,  0.0000, 20.7776, 16.0000,  0.0000,\n",
      "        17.8555,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 34.6357,  0.0000,\n",
      "        25.6045,  0.0000,  0.0000, 39.8455,  0.0000, 11.5262,  0.0000, 25.3086,\n",
      "        34.2564,  7.7979,  8.5917,  0.0000,  0.0000,  0.0000,  0.0000, 14.8221,\n",
      "         0.0000,  5.7044,  0.0000, 17.7644, 16.4708,  0.4104,  0.0000,  0.0000,\n",
      "        17.3969,  0.0000, 28.4139,  0.0000,  0.0000,  0.0000, 22.1028,  0.0000,\n",
      "         0.0000, 22.3774, 29.9852,  0.0000,  3.0627,  0.0000, 15.5124, 10.1516,\n",
      "        15.7410, 20.4040, 15.1884, 35.8185], device='cuda:0') \n",
      "\n",
      "Test Loss (mean squared error): 3.372026\n",
      "\n",
      "Test Loss Real (mean squared error): 4.478966\n",
      "\n",
      "Time: 198.70813512802124\n",
      "Max loss: 25.87344741821289\n",
      "targets: [-10.0, -10.0, -10.0]\n",
      "output: [-10.0, -10.0, -10.0]\n",
      "max_count: 50\n"
     ]
    }
   ],
   "source": [
    "# \"\"\" TESTING OF IMPORTED MODEL \"\"\"\n",
    "# os.chdir(csvfilesMLLocation)\n",
    "\n",
    "# # Print out values and images that have large differences in target/value\n",
    "# #importModelPath = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/csvdata9000/model_BCI.pt\"\n",
    "# #importModelPath = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new/BCI-ML/Good_Models/model_BCItrainbigf.pt\"\n",
    "# importModelPath = r\"C:/Users/Peter/Desktop/Thermo_R_Code/FinalThermo/new2/csvdataFULL/BCIML_Dataset/model_BCI.pt\"\n",
    "# # Track test loss\n",
    "# test_loss = 0.0\n",
    "# num_predictions = len(test_indices)\n",
    "\n",
    "# # Import model\n",
    "# model2 = BCIModel()\n",
    "# model2.cuda()\n",
    "# model2.load_state_dict(torch.load(importModelPath))\n",
    "\n",
    "# # check if CUDA is available\n",
    "# train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "# if not train_on_gpu:\n",
    "#     print('CUDA is not available.  Training on CPU ...')\n",
    "# else:\n",
    "#     print('CUDA is available!  Training on GPU ...')\n",
    "#     model2.cuda()\n",
    "\n",
    "# # Puts model will notify all your layers that you are in eval mode, that way, \n",
    "# # batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "# model2.eval()\n",
    "\n",
    "# max_loss = -10.0\n",
    "# targetList = [-10.0,-10.0,-10.0]\n",
    "# outputList = [-10.0,-10.0,-10.0]\n",
    "\n",
    "# thresh_max = 13\n",
    "# max_count = 0\n",
    "# not_included_count = 0\n",
    "\n",
    "# start = time.time()\n",
    "# counter = 0\n",
    "# predictions_divide_three = 0\n",
    "# test_loss_real = 0\n",
    "# # Iterate over test data\n",
    "# with torch.no_grad():\n",
    "#     for data, target in test_loader:\n",
    "#         predictions_divide_three += 1\n",
    "#         data, target = data.float(), target.float()\n",
    "#         # Move tensors to GPU if CUDA is available\n",
    "#         if train_on_gpu:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "#         # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "#         output = model2(data)\n",
    "#         output = torch.flatten(output)\n",
    "#         # Calculate the batch loss\n",
    "#         loss = criterion(output, target)\n",
    "        \n",
    "#         if(loss.item() > thresh_max):\n",
    "#             max_count += 1\n",
    "        \n",
    "#         if(loss.item() > max_loss):\n",
    "#             max_loss = loss.item()\n",
    "# #             for num in range(batch_size):\n",
    "# #                 targetList[num] = target[num].item()\n",
    "# #                 outputList[num] = output[num].item()\n",
    "        \n",
    "        \n",
    "#         test_loss_real += loss.item()\n",
    "#         # Update test loss\n",
    "#         if(loss.item() < thresh_max):\n",
    "#             test_loss += loss.item()\n",
    "#         else:\n",
    "#             not_included_count += 1\n",
    "        \n",
    "#         #print(type(target[0].item()))\n",
    "        \n",
    "#         #raise Exception(\"DO NOT TRAIN, EVALUATION ONLY\")\n",
    "        \n",
    "#         # Example data tensors\n",
    "#         if counter < 10:\n",
    "#             print(\"test loss from\", counter, \":\", loss.item())\n",
    "#             print(\"Output of network:\\t\", output)\n",
    "#             print(\"Target Values:\\t\\t\", target,\"\\n\")\n",
    "#             counter += 1\n",
    "        \n",
    "#     test_loss = test_loss/((predictions_divide_three-not_included_count)*3)\n",
    "#     test_loss_real = test_loss_real/(predictions_divide_three*3)\n",
    "#     print('Test Loss (mean squared error): {:.6f}\\n'.format(test_loss))\n",
    "#     print('Test Loss Real (mean squared error): {:.6f}\\n'.format(test_loss_real))\n",
    "# print(f'Time: {time.time()-start}')\n",
    "\n",
    "# print(\"Max loss:\", max_loss)\n",
    "# print(\"targets:\", targetList)\n",
    "# print(\"output:\", outputList)\n",
    "# print(\"max_count:\", max_count)\n",
    "\n",
    "\n",
    "\n",
    "#look at difference between with and without bigerros"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Dataset_CNN_fin2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
